{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarVinikoi/DL_NafldReserch/blob/main/ImageClassif_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdEZNvX4oN05",
        "outputId": "73369615-89cb-4664-9af3-f4c0612603cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tcn\n",
            "  Downloading keras_tcn-3.5.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-tcn) (1.22.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-tcn) (2.12.0)\n",
            "Collecting tensorflow-addons (from keras-tcn)\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.4.8)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.32.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->keras-tcn)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->keras-tcn) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->keras-tcn) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->keras-tcn) (3.2.2)\n",
            "Installing collected packages: typeguard, tensorflow-addons, keras-tcn\n",
            "Successfully installed keras-tcn-3.5.0 tensorflow-addons-0.20.0 typeguard-2.13.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tcn\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV7IBG9rrQwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb7e990-b0f8-4773-bb6b-576d2acaff07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PesquisaNAFLD/Data/NafldClassificationImage\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/PesquisaNAFLD/Data/NafldClassificationImage/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hRtATOdLzm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d77f190-2812-46c8-a8d2-b1bf2a8e38dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<module 'tensorflow._api.v2.version' from '/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/version/__init__.py'>\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.keras import callbacks\n",
        "from tcn import TCN, tcn_full_summary\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob, os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pandas as pd\n",
        "\n",
        "print(tf.version)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%python3 --version\n",
        "\n",
        "cv2.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NxDYYFCfNXdx",
        "outputId": "bc2457c3-d8de-48d7-84d5-804bb9aa25a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK6mq3-ttFGD",
        "outputId": "607f1bf9-a6d6-485a-aa87-24c7f1360424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6Fr03h8qBzj"
      },
      "outputs": [],
      "source": [
        "#Variáveis Globais\n",
        "\n",
        "path_doentes = \"images/doentes\"\n",
        "path_saudaveis = \"images/nao_doentes\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYVFbELuQull",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6578041-192b-4a94-b0bf-28eafdaeeb52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images/doentes/doente_1\n",
            "image 0 = images/doentes/doente_1/IR_41519.jpg\n",
            "image 4 = images/doentes/doente_1/IR_41527.jpg\n",
            "image 7 = images/doentes/doente_1/IR_41533.jpg\n",
            "images/doentes/doente_2\n",
            "image 0 = images/doentes/doente_2/IR_41355.jpg\n",
            "image 2 = images/doentes/doente_2/IR_41359.jpg\n",
            "image 5 = images/doentes/doente_2/IR_41367.jpg\n",
            "images/doentes/doente_3\n",
            "image 0 = images/doentes/doente_3/IR_41023.jpg\n",
            "image 2 = images/doentes/doente_3/IR_41027.jpg\n",
            "image 5 = images/doentes/doente_3/IR_41033.jpg\n",
            "images/doentes/doente_4\n",
            "image 0 = images/doentes/doente_4/IR_43059.jpg\n",
            "image 2 = images/doentes/doente_4/IR_43063.jpg\n",
            "image 5 = images/doentes/doente_4/IR_43069.jpg\n",
            "images/doentes/doente_5\n",
            "image 0 = images/doentes/doente_5/IR_41473.jpg\n",
            "image 6 = images/doentes/doente_5/IR_41485.jpg\n",
            "image 11 = images/doentes/doente_5/IR_41497.jpg\n",
            "images/doentes/doente_6\n",
            "image 0 = images/doentes/doente_6/IR_41455.jpg\n",
            "image 4 = images/doentes/doente_6/IR_41465.jpg\n",
            "image 7 = images/doentes/doente_6/IR_41471.jpg\n",
            "images/doentes/doente_7\n",
            "image 0 = images/doentes/doente_7/IR_41499.jpg\n",
            "image 4 = images/doentes/doente_7/IR_41509.jpg\n",
            "image 7 = images/doentes/doente_7/IR_41515.jpg\n",
            "images/doentes/doente_8\n",
            "image 0 = images/doentes/doente_8/image_1.jpg\n",
            "image 2 = images/doentes/doente_8/image_3.jpg\n",
            "image 5 = images/doentes/doente_8/image_6.jpg\n",
            "images/doentes/doente_9\n",
            "image 0 = images/doentes/doente_9/image_1.jpg\n",
            "image 2 = images/doentes/doente_9/image_3.jpg\n",
            "image 4 = images/doentes/doente_9/image_5.jpg\n",
            "images/doentes/doente_10\n",
            "image 0 = images/doentes/doente_10/image_1.jpg\n",
            "image 2 = images/doentes/doente_10/image_3.jpg\n",
            "image 5 = images/doentes/doente_10/image_6.jpg\n",
            "images/doentes/doente_11\n",
            "image 0 = images/doentes/doente_11/image_1.jpg\n",
            "image 2 = images/doentes/doente_11/image_3.jpg\n",
            "image 4 = images/doentes/doente_11/image_5.jpg\n",
            "images/doentes/doente_12\n",
            "image 0 = images/doentes/doente_12/IR_43105.jpg\n",
            "image 2 = images/doentes/doente_12/IR_43109.jpg\n",
            "image 5 = images/doentes/doente_12/IR_43115.jpg\n",
            "images/doentes/doente_13\n",
            "image 0 = images/doentes/doente_13/IR_41535.jpg\n",
            "image 2 = images/doentes/doente_13/IR_41539.jpg\n",
            "image 4 = images/doentes/doente_13/IR_41543.jpg\n",
            "images/doentes/doente_14\n",
            "image 0 = images/doentes/doente_14/IR_41287.jpg\n",
            "image 2 = images/doentes/doente_14/IR_41293.jpg\n",
            "image 5 = images/doentes/doente_14/IR_41299.jpg\n",
            "images/doentes/doente_15\n",
            "image 0 = images/doentes/doente_15/IR_41383.jpg\n",
            "image 2 = images/doentes/doente_15/IR_41387.jpg\n",
            "image 4 = images/doentes/doente_15/IR_41391.jpg\n",
            "images/doentes/doente_16\n",
            "image 0 = images/doentes/doente_16/IR_43045.jpg\n",
            "image 2 = images/doentes/doente_16/IR_43049.jpg\n",
            "image 4 = images/doentes/doente_16/IR_43053.jpg\n",
            "images/doentes/doente_17\n",
            "image 0 = images/doentes/doente_17/IR_43035.jpg\n",
            "image 2 = images/doentes/doente_17/IR_43039.jpg\n",
            "image 4 = images/doentes/doente_17/IR_43043.jpg\n",
            "images/doentes/doente_18\n",
            "image 0 = images/doentes/doente_18/IR_41319.jpg\n",
            "image 2 = images/doentes/doente_18/IR_41323.jpg\n",
            "image 4 = images/doentes/doente_18/IR_41327.jpg\n",
            "images/nao_doentes/nao_doente_1\n",
            "image 0 = images/nao_doentes/nao_doente_1/IR_31169.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_1/IR_31171.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_1/IR_31173.jpg\n",
            "images/nao_doentes/nao_doente_2\n",
            "image 0 = images/nao_doentes/nao_doente_2/IR_43189.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_2/IR_43193.jpg\n",
            "image 5 = images/nao_doentes/nao_doente_2/IR_43199.jpg\n",
            "images/nao_doentes/nao_doente_3\n",
            "image 0 = images/nao_doentes/nao_doente_3/IR_12190.jpg\n",
            "image 7 = images/nao_doentes/nao_doente_3/IR_13598.jpg\n",
            "image 14 = images/nao_doentes/nao_doente_3/IR_14449.jpg\n",
            "images/nao_doentes/nao_doente_4\n",
            "image 0 = images/nao_doentes/nao_doente_4/IR_43129.jpg\n",
            "image 3 = images/nao_doentes/nao_doente_4/IR_43135.jpg\n",
            "image 6 = images/nao_doentes/nao_doente_4/IR_43141.jpg\n",
            "images/nao_doentes/nao_doente_5\n",
            "image 0 = images/nao_doentes/nao_doente_5/IR_38783.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_5/IR_38979.jpg\n",
            "image 8 = images/nao_doentes/nao_doente_5/IR_38987.jpg\n",
            "images/nao_doentes/nao_doente_6\n",
            "image 0 = images/nao_doentes/nao_doente_6/IR_37663.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_6/IR_37671.jpg\n",
            "image 7 = images/nao_doentes/nao_doente_6/IR_38045.jpg\n",
            "images/nao_doentes/nao_doente_7\n",
            "image 0 = images/nao_doentes/nao_doente_7/IR_42853.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_7/IR_42857.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_7/IR_42861.jpg\n",
            "images/nao_doentes/nao_doente_8\n",
            "image 0 = images/nao_doentes/nao_doente_8/IR_43143.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_8/IR_43147.jpg\n",
            "image 5 = images/nao_doentes/nao_doente_8/IR_43153.jpg\n",
            "images/nao_doentes/nao_doente_9\n",
            "image 0 = images/nao_doentes/nao_doente_9/IR_42395.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_9/IR_42399.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_9/IR_42403.jpg\n",
            "images/nao_doentes/nao_doente_10\n",
            "image 0 = images/nao_doentes/nao_doente_10/IR_39286.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_10/IR_39290.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_10/IR_39294.jpg\n",
            "images/nao_doentes/nao_doente_11\n",
            "image 0 = images/nao_doentes/nao_doente_11/IR_15044.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_11/IR_15048.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_11/IR_15052.jpg\n",
            "images/nao_doentes/nao_doente_12\n",
            "image 0 = images/nao_doentes/nao_doente_12/IR_15710.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_12/IR_15714.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_12/IR_15718.jpg\n",
            "images/nao_doentes/nao_doente_13\n",
            "image 0 = images/nao_doentes/nao_doente_13/IR_14984.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_13/IR_14988.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_13/IR_14992.jpg\n",
            "images/nao_doentes/nao_doente_14\n",
            "image 0 = images/nao_doentes/nao_doente_14/IR_15592.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_14/IR_15596.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_14/IR_15600.jpg\n",
            "images/nao_doentes/nao_doente_15\n",
            "image 0 = images/nao_doentes/nao_doente_15/IR_42895.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_15/IR_42899.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_15/IR_42903.jpg\n",
            "images/nao_doentes/nao_doente_16\n",
            "image 0 = images/nao_doentes/nao_doente_16/IR_42355.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_16/IR_42359.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_16/IR_42363.jpg\n",
            "images/nao_doentes/nao_doente_17\n",
            "image 0 = images/nao_doentes/nao_doente_17/IR_16354.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_17/IR_16358.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_17/IR_16362.jpg\n",
            "images/nao_doentes/nao_doente_18\n",
            "image 0 = images/nao_doentes/nao_doente_18/IR_43175.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_18/IR_43179.jpg\n",
            "image 5 = images/nao_doentes/nao_doente_18/IR_43185.jpg\n",
            "images/nao_doentes/nao_doente_19\n",
            "image 0 = images/nao_doentes/nao_doente_19/IR_43155.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_19/IR_43159.jpg\n",
            "image 5 = images/nao_doentes/nao_doente_19/IR_43165.jpg\n",
            "images/nao_doentes/nao_doente_20\n",
            "image 0 = images/nao_doentes/nao_doente_20/IR_26684.jpg\n",
            "image 1 = images/nao_doentes/nao_doente_20/IR_26686.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_20/IR_26688.jpg\n",
            "images/nao_doentes/nao_doente_21\n",
            "image 0 = images/nao_doentes/nao_doente_21/IR_43201.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_21/IR_43205.jpg\n",
            "image 5 = images/nao_doentes/nao_doente_21/IR_43211.jpg\n",
            "images/nao_doentes/nao_doente_22\n",
            "image 0 = images/nao_doentes/nao_doente_22/IR_26958.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_22/IR_26962.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_22/IR_26966.jpg\n",
            "Len vetor final de doentes: 54\n",
            "Len vetor final de saudáveis: 66\n",
            "Estado dos conjuntos:\n",
            "Treino: 288 -- Labels: 288\n",
            "Teste: 24 -- Labels: 24\n",
            "Val: 24 -- Labels: 24\n",
            "Estado dos conjuntos:\n",
            "Treino: 96 -- Labels: 96\n",
            "Teste: 8 -- Labels: 8\n",
            "Val: 8 -- Labels: 8\n",
            "(96, 3, 40000)\n",
            "(8, 3, 40000)\n",
            "(8, 3, 40000)\n",
            "Labels de Treino: (0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1)\n",
            "Labels de Teste: (1, 0, 1, 0, 1, 0, 0, 1)\n",
            "Labels de Validação: (1, 0, 0, 1, 1, 0, 0, 1)\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 5s 789ms/step - loss: 6511.9727 - accuracy: 0.4479 - val_loss: 7619.9458 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as tcn_1_layer_call_fn, tcn_1_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, residual_block_0_layer_call_fn while saving (showing 5 of 133). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/50\n",
            "3/3 [==============================] - 1s 381ms/step - loss: 5080.6851 - accuracy: 0.4688 - val_loss: 123.2020 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 1s 391ms/step - loss: 1512.7915 - accuracy: 0.4896 - val_loss: 2623.3093 - val_accuracy: 0.5000\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 1s 381ms/step - loss: 2224.8030 - accuracy: 0.5521 - val_loss: 1353.8590 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 1s 386ms/step - loss: 1192.9430 - accuracy: 0.4271 - val_loss: 513.2789 - val_accuracy: 0.5000\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 1s 364ms/step - loss: 354.9997 - accuracy: 0.5625 - val_loss: 1579.4159 - val_accuracy: 0.5000\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 1s 378ms/step - loss: 956.1525 - accuracy: 0.5521 - val_loss: 1395.1018 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 1s 388ms/step - loss: 996.9187 - accuracy: 0.4479 - val_loss: 1856.4756 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 1s 477ms/step - loss: 2319.4177 - accuracy: 0.5521 - val_loss: 1900.2074 - val_accuracy: 0.5000\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 2s 743ms/step - loss: 880.1118 - accuracy: 0.6667 - val_loss: 2252.0098 - val_accuracy: 0.5000\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 1s 404ms/step - loss: 1263.7596 - accuracy: 0.5312 - val_loss: 1281.5598 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 1s 386ms/step - loss: 787.2497 - accuracy: 0.5521 - val_loss: 785.8331 - val_accuracy: 0.5000\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 1s 375ms/step - loss: 563.9604 - accuracy: 0.4583 - val_loss: 1112.1689 - val_accuracy: 0.5000\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 1s 389ms/step - loss: 1368.3890 - accuracy: 0.5521 - val_loss: 979.1793 - val_accuracy: 0.5000\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 1s 376ms/step - loss: 796.2619 - accuracy: 0.4896 - val_loss: 940.4919 - val_accuracy: 0.5000\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 1s 376ms/step - loss: 363.3102 - accuracy: 0.6667 - val_loss: 1204.2404 - val_accuracy: 0.5000\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 1s 392ms/step - loss: 317.7719 - accuracy: 0.6562 - val_loss: 1173.9832 - val_accuracy: 0.5000\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 1s 405ms/step - loss: 467.9058 - accuracy: 0.6146 - val_loss: 1099.8926 - val_accuracy: 0.5000\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 1s 390ms/step - loss: 425.4903 - accuracy: 0.6458 - val_loss: 336.1425 - val_accuracy: 0.5000\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 4s 1s/step - loss: 183.4985 - accuracy: 0.6979 - val_loss: 376.4214 - val_accuracy: 0.5000\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 2s 729ms/step - loss: 148.2956 - accuracy: 0.7292 - val_loss: 147.6700 - val_accuracy: 0.6250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as tcn_1_layer_call_fn, tcn_1_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, residual_block_0_layer_call_fn while saving (showing 5 of 133). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/50\n",
            "3/3 [==============================] - 1s 395ms/step - loss: 128.7562 - accuracy: 0.7708 - val_loss: 188.6119 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 2s 588ms/step - loss: 53.1174 - accuracy: 0.8229 - val_loss: 161.5566 - val_accuracy: 0.3750\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 2s 630ms/step - loss: 28.4335 - accuracy: 0.8854 - val_loss: 184.9464 - val_accuracy: 0.6250\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 1s 466ms/step - loss: 11.8872 - accuracy: 0.9583 - val_loss: 518.4237 - val_accuracy: 0.5000\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 1s 445ms/step - loss: 7.9820 - accuracy: 0.9167 - val_loss: 227.1754 - val_accuracy: 0.6250\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 1s 384ms/step - loss: 12.3178 - accuracy: 0.9479 - val_loss: 248.4702 - val_accuracy: 0.6250\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 1s 396ms/step - loss: 3.5990 - accuracy: 0.9792 - val_loss: 288.1565 - val_accuracy: 0.3750\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 1s 389ms/step - loss: 2.8464 - accuracy: 0.9792 - val_loss: 488.6924 - val_accuracy: 0.5000\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 1s 374ms/step - loss: 3.3142 - accuracy: 0.9583 - val_loss: 228.6237 - val_accuracy: 0.6250\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 1s 377ms/step - loss: 7.3413 - accuracy: 0.9583 - val_loss: 256.0367 - val_accuracy: 0.6250\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 1s 383ms/step - loss: 0.3161 - accuracy: 0.9896 - val_loss: 235.9918 - val_accuracy: 0.5000\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 2s 581ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 420.0396 - val_accuracy: 0.3750\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 2s 634ms/step - loss: 0.1404 - accuracy: 0.9896 - val_loss: 455.6488 - val_accuracy: 0.3750\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 2s 633ms/step - loss: 0.3238 - accuracy: 0.9896 - val_loss: 367.2654 - val_accuracy: 0.3750\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 1s 462ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 302.2476 - val_accuracy: 0.3750\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 1s 401ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 261.8000 - val_accuracy: 0.5000\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 1s 389ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 239.5270 - val_accuracy: 0.3750\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 1s 410ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 231.2032 - val_accuracy: 0.5000\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 1s 393ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 231.7617 - val_accuracy: 0.5000\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 1s 399ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 232.2685 - val_accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 1s 386ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 232.6213 - val_accuracy: 0.5000\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 2s 631ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 232.8762 - val_accuracy: 0.5000\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 2s 543ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 233.0659 - val_accuracy: 0.5000\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 2s 684ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 233.1675 - val_accuracy: 0.5000\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 2s 415ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 233.2302 - val_accuracy: 0.5000\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 1s 393ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 233.2760 - val_accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 1s 400ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 233.3107 - val_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 1s 394ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 233.3352 - val_accuracy: 0.5000\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 1s 413ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 233.3536 - val_accuracy: 0.5000\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "module_wrapper_2 (ModuleWrap (None, 64)                10400704  \n",
            "_________________________________________________________________\n",
            "module_wrapper_3 (ModuleWrap (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 10,400,769\n",
            "Trainable params: 10,400,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Prediction Shape:\n",
            "0    -    1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-622d512d5fd4>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-622d512d5fd4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m#numImgs(True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#model = tf.keras.models.load_model(\"/content/drive/MyDrive/PesquisaNAFLD/Data/NafldClassificationImage/images/Melhores Modelos/model.26-0.78\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-b75b41dc9c07>\u001b[0m in \u001b[0;36mloadData\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_treino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_teste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_treino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_teste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b10ecad3a370>\u001b[0m in \u001b[0;36mclassifier\u001b[0;34m(train_set, test_set, val_set, train_label_set, test_label_set, val_label_set, model, track_paths)\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"1    -    {test_label_set[i]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mimage_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;31m#Salvando o modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "  #dataAugmentation(True) #Só executa com o parametro setado em True\n",
        "  #paddingImages()\n",
        "\n",
        "\n",
        "  #numImgs(True)\n",
        "  #model = tf.keras.models.load_model(\"/content/drive/MyDrive/PesquisaNAFLD/Data/NafldClassificationImage/images/Melhores Modelos/model.26-0.78\")\n",
        "  loadData()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CpaxCULMHwy"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Função encarregada de carregar os dados em memória e chamar a função para realização do treino.\n",
        "def loadData(model = None):\n",
        "  timesteps = 3\n",
        "  treino = []\n",
        "  teste = []\n",
        "  val = []\n",
        "\n",
        "  labels_treino = []\n",
        "  labels_teste = []\n",
        "  labels_val = []\n",
        "\n",
        "\n",
        "  vetor_imgs_doe = []\n",
        "  vetor_imgs_sau = []\n",
        "  vetor_final_imgs = []\n",
        "\n",
        "  #Carregando os vetores de imagens e os transformando em séries temporais\n",
        "  #Vetor de Doentes\n",
        "  for paciente in os.listdir(path_doentes):\n",
        "    path_paciente = os.path.join(path_doentes, paciente)\n",
        "    print(path_paciente)\n",
        "    paths_imgs = sorted(glob.glob(os.path.join(path_paciente, \"*.jpg\")))\n",
        "    for i, img_path in enumerate(paths_imgs):\n",
        "      #Se a imagem for a primeira, última ou do meio, iremos operar sobre ela\n",
        "      if(img_path == paths_imgs[0] or img_path == paths_imgs[-1] or img_path == paths_imgs[round((len(paths_imgs)-1)/2)]):\n",
        "        image = cv2.imread(img_path)\n",
        "        print(f\"image {i} = {img_path}\")\n",
        "        \n",
        "        vetor_imgs_doe.append(image)\n",
        "\n",
        "  #LABELS --> 0 = DOENTES  ||  1 = SAUDÁVEIS\n",
        "  #labels.extend(np.zeros(len(vetor_final_imgs)/timesteps), dtype = \"int32\")\n",
        "\n",
        "  #Vetor de Saudáveis\n",
        "  for paciente in os.listdir(path_saudaveis):\n",
        "    path_paciente = os.path.join(path_saudaveis, paciente)\n",
        "    paths_imgs = sorted(glob.glob(os.path.join(path_paciente, \"*.jpg\")))\n",
        "    print(path_paciente)\n",
        "    for i, img_path in enumerate(paths_imgs):\n",
        "      #Se a imagem for a primeira, última ou do meio, iremos operar sobre ela\n",
        "      if(img_path == paths_imgs[0] or img_path == paths_imgs[-1] or img_path == paths_imgs[round((len(paths_imgs)-1)/2)]):\n",
        "        \n",
        "        image = cv2.imread(img_path)\n",
        "        vetor_imgs_sau.append(image)\n",
        "        print(f\"image {i} = {img_path}\")\n",
        "\n",
        "\n",
        "  #LABELS --> 0 = DOENTES  ||  1 = SAUDÁVEIS\n",
        "  #labels.extend(np.ones(len(vetor_final_imgs) - len(labels)))\n",
        "\n",
        "\n",
        "\n",
        "  print(f\"Len vetor final de doentes: {len(vetor_imgs_doe)}\")\n",
        "  print(f\"Len vetor final de saudáveis: {len(vetor_imgs_sau)}\")\n",
        "\n",
        "  \n",
        "  treino_doe = []\n",
        "  treino_sau = []\n",
        "  #Utilizando cerca de 60% das imagens para treino\n",
        "  treino_doe.extend(vetor_imgs_doe[:round(len(vetor_imgs_doe)*0.6)])\n",
        "  treino_sau.extend(vetor_imgs_sau[:round(len(vetor_imgs_sau)*0.6)])\n",
        "\n",
        "  treino, labels_treino = dataAugmentation(treino_doe, treino_sau)\n",
        "\n",
        "  #Utilizando cerca de 20% das imagens para teste\n",
        "  teste.extend(vetor_imgs_doe[round(len(vetor_imgs_doe)*0.6):round(len(vetor_imgs_doe)*0.8)])\n",
        "  labels_teste = [0 for x in range(len(teste))]\n",
        "  teste.extend(vetor_imgs_sau[round(len(vetor_imgs_sau)*0.6):round(len(vetor_imgs_sau)*0.8)])\n",
        "  labels_teste.extend(1 for x in range(len(teste)-len(labels_teste)))\n",
        "\n",
        "\n",
        "  #Utilizando cerca de 15% das imagens para validação\n",
        "  val.extend(vetor_imgs_doe[round(len(vetor_imgs_doe)*0.8):])\n",
        "  labels_val = [0 for x in range(len(val))]\n",
        "  val.extend(vetor_imgs_sau[round(len(vetor_imgs_sau)*0.8):])\n",
        "  labels_val.extend(1 for x in range(len(val)-len(labels_val)))\n",
        "\n",
        "\n",
        "  #Conversão para Séries Temporais\n",
        "\n",
        "  \n",
        "  print(\"Estado dos conjuntos:\")\n",
        "  print(f\"Treino: {len(treino)} -- Labels: {len(labels_treino)}\")\n",
        "  print(f\"Teste: {len(teste)} -- Labels: {len(labels_teste)}\")\n",
        "  print(f\"Val: {len(val)} -- Labels: {len(labels_val)}\")\n",
        "\n",
        "  treino, teste, val, labels_treino, labels_teste, labels_val = toTemporal(treino, teste, val, labels_treino, labels_teste, labels_val)\n",
        "\n",
        "\n",
        "  treino = np.array(treino)\n",
        "  teste = np.array(teste)\n",
        "  val = np.array(val)\n",
        "\n",
        "  print(treino.shape)\n",
        "  print(teste.shape)\n",
        "  print(val.shape)\n",
        "\n",
        "\n",
        "\n",
        "  #Embaralhando os vetores de imagens térmicas\n",
        "  \n",
        "  random.seed(852741)\n",
        "\n",
        "  zipped_treino = list(zip(treino, labels_treino))\n",
        "  zipped_teste = list(zip(teste, labels_teste))\n",
        "  zipped_val = list(zip(val, labels_val))\n",
        "\n",
        "\n",
        "  random.shuffle(zipped_treino)\n",
        "  random.shuffle(zipped_teste)\n",
        "  random.shuffle(zipped_val)\n",
        "\n",
        "  treino, labels_treino = zip(*zipped_treino)\n",
        "  teste, labels_teste = zip(*zipped_teste)\n",
        "  val, labels_val = zip(*zipped_val)\n",
        "\n",
        "\n",
        "\n",
        "  print(f\"Labels de Treino: {labels_treino}\")\n",
        "  print(f\"Labels de Teste: {labels_teste}\")\n",
        "  print(f\"Labels de Validação: {labels_val}\")\n",
        "  \n",
        "  treino = np.array(treino)\n",
        "  teste = np.array(teste)\n",
        "  val = np.array(val)\n",
        "  labels_treino = np.array(labels_treino)\n",
        "  labels_teste = np.array(labels_teste)\n",
        "  labels_val = np.array(labels_val)\n",
        "\n",
        "\n",
        "  if model != None:\n",
        "    classifier(treino, teste, val, labels_treino, labels_teste, labels_val, model)\n",
        "  else:\n",
        "    classifier(treino, teste, val, labels_treino, labels_teste, labels_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def toTemporal(v_treino, v_teste, v_val, labels_treino, labels_teste, labels_val):\n",
        "  v_final_treino = []\n",
        "  v_final_teste = []\n",
        "  v_final_val = []\n",
        "  labels_final_treino = []\n",
        "  labels_final_teste = []\n",
        "  labels_final_val = []\n",
        "  v_imgs = []\n",
        "\n",
        "  for i, elm in enumerate(v_treino):\n",
        "\n",
        "    r_img, g_img, b_img = cv2.split(elm)\n",
        "      \n",
        "    r_img = np.array(r_img)\n",
        "    r_img = np.ndarray.flatten(r_img)\n",
        "    \n",
        "    v_imgs.append(r_img)\n",
        "\n",
        "    if len(v_imgs) == 3:\n",
        "      v_final_treino.append((v_imgs[0], v_imgs[1], v_imgs[2]))\n",
        "      v_imgs.clear()\n",
        "\n",
        "\n",
        "  for elm in v_teste:\n",
        "    \n",
        "    r_img, g_img, b_img = cv2.split(elm)\n",
        "      \n",
        "    r_img = np.array(r_img)\n",
        "    r_img = np.ndarray.flatten(r_img)\n",
        "\n",
        "    v_imgs.append(r_img)\n",
        "  \n",
        "    if len(v_imgs) == 3:\n",
        "      v_final_teste.append((v_imgs[0], v_imgs[1], v_imgs[2]))\n",
        "      v_imgs.clear()\n",
        "\n",
        "  \n",
        "  for elm in v_val:\n",
        "\n",
        "    r_img, g_img, b_img = cv2.split(elm)\n",
        "      \n",
        "    r_img = np.array(r_img)\n",
        "    r_img = np.ndarray.flatten(r_img)\n",
        "\n",
        "    v_imgs.append(r_img)\n",
        "\n",
        "    if len(v_imgs) == 3:\n",
        "      v_final_val.append((v_imgs[0], v_imgs[1], v_imgs[2]))\n",
        "      v_imgs.clear()\n",
        "\n",
        "  for i in range(0,len(labels_treino),3):\n",
        "    labels_final_treino.append(labels_treino[i])\n",
        "\n",
        "  for i in range(0,len(labels_teste),3):\n",
        "    labels_final_teste.append(labels_teste[i])\n",
        "\n",
        "  for i in range(0,len(labels_val),3):\n",
        "    labels_final_val.append(labels_val[i])\n",
        "\n",
        "  print(\"Estado dos conjuntos:\")\n",
        "  print(f\"Treino: {len(v_final_treino)} -- Labels: {len(labels_final_treino)}\")\n",
        "  print(f\"Teste: {len(v_final_teste)} -- Labels: {len(labels_final_teste)}\")\n",
        "  print(f\"Val: {len(v_final_val)} -- Labels: {len(labels_final_val)}\")\n",
        "    \n",
        "  return (v_final_treino, v_final_teste, v_final_val, labels_final_treino, labels_final_teste, labels_final_val)"
      ],
      "metadata": {
        "id": "tOmt8bASk_ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier(train_set, test_set, val_set, train_label_set, test_label_set, val_label_set, model = None, track_paths = None):\n",
        "\n",
        "  callback_funcs = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath = \"model.{epoch:02d}-{val_accuracy:.2f}\", monitor=\"val_accuracy\", save_best_only=True),\n",
        "  ]\n",
        "\n",
        "  if(model == None):\n",
        "    model = Sequential([\n",
        "        TCN(nb_filters = 64, kernel_initializer=\"glorot_uniform\", dilations = (1,2,4,8,16,32,64)),\n",
        "        tf.keras.layers.Dense(units=1,activation=\"sigmoid\")\n",
        "        \n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=\"adam\", loss = tf.losses.BinaryFocalCrossentropy(), metrics = [\"accuracy\"])\n",
        "    print(\"\\n\\n\")\n",
        "    \n",
        "    hist = model.fit(train_set, train_label_set, validation_data=(val_set, val_label_set), epochs=50, callbacks = callback_funcs)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "  yhat = model.predict(test_set)\n",
        "\n",
        "  print(\"Prediction Shape:\")\n",
        "  evaluated = []\n",
        "  expected = np.ndarray.tolist(test_label_set)\n",
        "\n",
        "  for i, val in enumerate(yhat):\n",
        "    \n",
        "    if val < .5:\n",
        "      evaluated.append(0)\n",
        "      print(f\"0    -    {test_label_set[i]}\")\n",
        "    else:\n",
        "      evaluated.append(1)\n",
        "      print(f\"1    -    {test_label_set[i]}\")\n",
        "\n",
        "    image_test = cv2.imread(track_paths[i])\n",
        "    cv2_imshow(image_test)\n",
        "  #Salvando o modelo\n",
        "  if os.path.isdir(\"/content/drive/MyDrive/PesquisaNAFLD/Data/NafldClassificationImage/last_model\") == False:\n",
        "    model.save(\"/content/drive/MyDrive/PesquisaNAFLD/Data/NafldClassificationImage/last_model\")\n",
        "\n",
        "  resModel(expected, evaluated)\n",
        "  \n",
        "\n",
        "def resModel(expected, evaluated):\n",
        "    \n",
        "  truePos=falsePos=falseNeg=trueNeg = 0\n",
        "  for i, val in enumerate(evaluated):\n",
        "\n",
        "    #Se o modelo previu a classe da imagem corretamente\n",
        "    if val == expected[i]:\n",
        "      #Elencando um verdadeiro positivo\n",
        "      if val == 0:\n",
        "        truePos += 1\n",
        "      #Elencando um verdadeiro negativo\n",
        "      else:\n",
        "        trueNeg += 1\n",
        "    #Se o modelo previu a classe da imagem incorretamente\n",
        "    else:\n",
        "      #Elencando um falso positivo\n",
        "      if val == 0:\n",
        "        falsePos += 1\n",
        "      else:\n",
        "        falseNeg += 1\n",
        "  print(\"\\n\\n\\t====== Elucidação dos Resultados ======\")\n",
        "  print(f\"Falsos Negativos: {falseNeg}\")\n",
        "  print(f\"Falsos Positivos: {falsePos}\")\n",
        "  print(f\"Verdadeiros Negativos: {trueNeg}\")\n",
        "  print(f\"Verdadeiros Positivos: {truePos}\")\n",
        "\n",
        "  print(f\"\\nAcurácia: {(truePos + trueNeg)/(truePos + falsePos + trueNeg + falseNeg):.2f}\")\n",
        "  print(f\"Sensibilidade: {truePos/(truePos + falseNeg):.2f}\")\n",
        "  print(f\"Especificidade: {trueNeg/(falsePos + trueNeg):.2f}\")\n",
        "  print(f\"Precisão: {truePos/(truePos + falsePos):.2f}\")"
      ],
      "metadata": {
        "id": "TMUu6mhONwRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Q8tjnahpxNc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def dataAugmentation(v_treino_doe : list, v_treino_sau):\n",
        "  labels = []\n",
        "  treino = []\n",
        "  lenght_doe = len(v_treino_doe)\n",
        "  lenght_sau = len(v_treino_sau)\n",
        "  for i in range(lenght_doe):\n",
        "    v_treino_doe.append(cv2.flip(v_treino_doe[i], 0))\n",
        "  for i in range(lenght_doe):\n",
        "    v_treino_doe.append(cv2.flip(v_treino_doe[i], 1))\n",
        "  for i in range(lenght_doe):\n",
        "    v_treino_doe.append(cv2.rotate(v_treino_doe[i], cv2.ROTATE_90_CLOCKWISE))\n",
        "  \n",
        "  for i in range(lenght_sau):\n",
        "    v_treino_sau.append(cv2.flip(v_treino_sau[i], 0))\n",
        "  for i in range(lenght_sau):\n",
        "    v_treino_sau.append(cv2.flip(v_treino_sau[i], 1))\n",
        "  for i in range(lenght_sau):\n",
        "    v_treino_sau.append(cv2.rotate(v_treino_sau[i], cv2.ROTATE_90_CLOCKWISE))\n",
        "\n",
        "  labels = [0 for x in range(len(v_treino_doe))]\n",
        "  labels.extend(1 for x in range(len(v_treino_sau)))\n",
        "\n",
        "  treino.extend(v_treino_doe)\n",
        "  treino.extend(v_treino_sau)\n",
        "\n",
        "  return (treino, labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def numImgs(supPrint = True):\n",
        "  cont_tot = 0\n",
        "  cont_doentes = 0\n",
        "  cont_saudaveis = 0\n",
        "  cont_paciente = 0\n",
        "\n",
        "  if supPrint == False:\n",
        "\n",
        "    for paciente in os.listdir(path_doentes):\n",
        "      path_paciente = os.path.join(path_doentes, paciente)\n",
        "      paths_imgs = sorted(glob.glob(os.path.join(path_paciente, \"*.jpg\")))\n",
        "      for img_path in (paths_imgs):\n",
        "        cont_tot += 1\n",
        "        cont_doentes += 1\n",
        "        cont_paciente += 1\n",
        "      print(path_paciente + f\": {cont_paciente}\")\n",
        "      cont_paciente = 0\n",
        "\n",
        "    for paciente in os.listdir(path_saudaveis):\n",
        "      path_paciente = os.path.join(path_saudaveis, paciente)\n",
        "      paths_imgs = sorted(glob.glob(os.path.join(path_paciente, \"*.jpg\")))\n",
        "      for i, img_path in enumerate(paths_imgs):\n",
        "        cont_tot += 1\n",
        "        cont_saudaveis += 1\n",
        "        cont_paciente += 1\n",
        "      print(path_paciente + f\": {cont_paciente}\")\n",
        "      cont_paciente = 0\n",
        "\n",
        "    print(f\"\\nTotal de imagens na base: {cont_tot}\")\n",
        "    print(f\"Total de imagens de pacientes doentes na base: {cont_doentes}\")\n",
        "    print(f\"Total de imagens de pacientes saudáveis na base: {cont_saudaveis}\")\n",
        "\n",
        "  return (cont_tot, cont_doentes, cont_saudaveis)"
      ],
      "metadata": {
        "id": "9msd-RN6KvJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing Layer\n",
        "\n",
        "import os, shutil\n",
        "import csv\n",
        "import matplotlib as mp\n",
        "from PIL import Image as img\n",
        "import numpy as np\n",
        "from scipy.signal import wiener #modulo para preprocessamento\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Definindo caminhos de onde vou tirar os csvs brutos\n",
        "abs_path = os.path.abspath(os.getcwd())#pegando o caminho absoluto(raiz)\n",
        "data_path = os.path.join(abs_path, 'raw_data') # pip install opencv-python-headlesscwd/raw_data\n",
        "sub = 'flir_export_2' #Escolhendo qual flir usar\n",
        "sub_path = os.path.join(data_path, sub)  #cwd/raw_data/ flir_export_1(varia de acordo com o escolhido na linha anterior)  \n",
        "#Definindo caminho de onde vou colocar os csvs\n",
        "csv_folder = os.path.join(abs_path, 'clean_csv') #cwd/clean_csv\n",
        "#Definindo caminho de onde vou colcar as imagens\n",
        "img_path = os.path.join(abs_path, 'images') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Renomeia os csvs e os limpa\n",
        "\n",
        "def clearCsv (sub_path):\n",
        "\n",
        "    if os.path.exists(csv_folder): \n",
        "        shutil.rmtree(csv_folder) #Remove a pasta, caso exista\n",
        "        pass\n",
        "\n",
        "    os.mkdir(csv_folder)#cria (ou recria) o diretório para os csvs\n",
        "    os.mkdir(os.path.join(csv_folder, 'doentes'))#criando subdiretório para doentes\n",
        "    os.mkdir(os.path.join(csv_folder, 'nao_doentes'))#para não doentes\n",
        "\n",
        "    for group in os.listdir(sub_path): # Doentes ou não doentes\n",
        "\n",
        "        group_path = os.path.join(sub_path, group) # cwd/raw_data/flir_export_1/(nao_)doentes\n",
        "        i = 1 # Numera os pacientes de cada grupo\n",
        "\n",
        "        for subject in os.listdir(group_path): # Para cada paciente dentro do seu grupo\n",
        "\n",
        "            subject_path = os.path.join(group_path, subject) # cwd/raw_data/flir_export_1/(nao_)doentes/paciente X\n",
        "\n",
        "            # Definindo e criando caminho da pasta de destino dos CSVs do paciente atual\n",
        "            if \"nao\" in group:\n",
        "                dest_sheet_path = os.path.join(csv_folder, 'nao_doentes',\n",
        "                    'nao_doente_{}'.format(i)) # cwd/clean_csv/nao_doentes/nao_doente_X\n",
        "            else:\n",
        "                dest_sheet_path = os.path.join(csv_folder,\n",
        "                    'doentes', 'doente_{}'.format(i)) # cwd/clean_csv/doentes/doente_X\n",
        "                pass\n",
        "\n",
        "            os.mkdir(dest_sheet_path)#criando pasta de destino para os csvs dos doentes\n",
        "            i += 1\n",
        "\n",
        "            for sheet in os.listdir(subject_path):\n",
        "                sheet_path = os.path.join(subject_path, sheet) # cwd/raw_data/flir_export_1/(nao_)doentes/paciente X/IR_XXXXX.csv\n",
        "\n",
        "                relevantRows = 0\n",
        "                topUselessRows = 0\n",
        "                relevantCols = 0\n",
        "            \n",
        "             # Tratando o CSV\n",
        "                with open(sheet_path) as sheet_file:\n",
        "                    sheet_array = csv.reader(sheet_file, delimiter=';')\n",
        "                    sheet_list = list(sheet_array)\n",
        "\n",
        "                    # Região hepática FLIR tem 4 linhas inúteis no topo e 1 no fundo\n",
        "                    # e uma coluna inútil à esquerda\n",
        "                    relevantRows = len(sheet_list) - 5\n",
        "                    topUselessRows = len(sheet_list) - relevantRows - 1\n",
        "                    relevantCols = len(sheet_list[10]) - 1\n",
        "\n",
        "                # Coletando o CSV sem a informação inútil\n",
        "                sheet_clear = pd.read_csv(sheet_path, skiprows=topUselessRows, nrows=relevantRows, \n",
        "                usecols=[i for i in range(1,relevantCols+1)], header=None, sep=';') \n",
        "                \n",
        "                # Salvando o CSV limpo no padrão ideal para converter em imagem\n",
        "                sheet_clear.to_csv(os.path.join(dest_sheet_path, sheet), \n",
        "                    index=False, header=False)\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Controla a geração de imagens térmicas em escala de cinza a partir dos CSVs e as melhora\n",
        "def generateImages():\n",
        "\n",
        "    # Definindo o caminho de origem e destino\n",
        "    source_path = csv_folder # cwd/data/csv\n",
        "\n",
        "    # Criando os diretórios de destino\n",
        "    if os.path.exists(img_path):\n",
        "        shutil.rmtree(img_path)\n",
        "    os.mkdir(img_path)\n",
        "    os.mkdir(os.path.join(img_path, 'doentes'))\n",
        "    os.mkdir(os.path.join(img_path, 'nao_doentes'))\n",
        "\n",
        "    # Definindo a temperatura máxima e mínima dentre todos os CSVs da base\n",
        "    tempMax = 0\n",
        "    tempMin = 40000\n",
        "    for group in os.listdir(source_path): # Doentes ou não doentes\n",
        "        group_path = os.path.join(source_path, group) # cwd/source_path/(nao_)doentes\n",
        "        for subject in os.listdir(group_path): # Pacientes\n",
        "            subject_path = os.path.join(group_path, subject) # cwd/source_path/(nao_)doentes/(nao_)doente_X\n",
        "            for sheet in os.listdir(subject_path): # Imagens\n",
        "                sheet_path = os.path.join(subject_path, sheet) # cwd/source_path/(nao_)doentes/(nao_)doente_X/IR_XXXXX.csv\n",
        "\n",
        "                sheet_array = pd.read_csv(sheet_path, header=None, decimal=\",\")\n",
        "                sheet_array = pd.DataFrame.to_numpy(sheet_array)\n",
        "                # Armazenando temperaturas sem casas decimais\n",
        "                localTempMax = int(np.max(sheet_array)*1000)\n",
        "                localTempMin = int(np.min(sheet_array)*1000)\n",
        "                if localTempMax > tempMax:\n",
        "                    tempMax = localTempMax\n",
        "                if localTempMin < tempMin:\n",
        "                    tempMin = localTempMin\n",
        "                #numRows, numCols = sheet_array.shape ##########\n",
        "                #if numRows > greaterDimension: ##########\n",
        "                #    imgSquareSize  = numRows ###########\n",
        "                #if numCols > greaterDimension: #######\n",
        "                #    imgSquareSize = numCols ##############\n",
        "\n",
        "    # Gerando as imagens térmicas\n",
        "    for group in os.listdir(source_path): # Doentes ou não doentes\n",
        "        group_path = os.path.join(source_path, group) # cwd/source_path/(nao_)doentes\n",
        "        for subject in os.listdir(group_path): # Pacientes\n",
        "            subject_path = os.path.join(group_path, subject) # cwd/source_path/(nao_)doentes/(nao_)doente_X\n",
        "            # Definindo e criando caminho da pasta de destino das imagens do paciente atual\n",
        "            if \"nao\" in group:\n",
        "                dest_image_path = os.path.join(img_path, 'nao_doentes', subject) # cwd/data/images/nao_doentes/nao_doente_X\n",
        "            else:\n",
        "                dest_image_path = os.path.join(img_path, 'doentes', subject) # cwd/data/images/doentes/doente_X\n",
        "            os.mkdir(dest_image_path)\n",
        "            for sheet in os.listdir(subject_path): # Imagens\n",
        "                sheet_path = os.path.join(subject_path, sheet) # cwd/source_path/(nao_)doentes/(nao_)doente_X/IR_XXXXX.csv\n",
        "\n",
        "                # Coletando o CSV\n",
        "                sheet_array = pd.read_csv(sheet_path, header=None, decimal=\",\")\n",
        "                sheet_array = pd.DataFrame.to_numpy(sheet_array)\n",
        "\n",
        "                # Convertendo o CSV para imagem térmica\n",
        "                image = toThermography(sheet_array, tempMin, tempMax)\n",
        "\n",
        "                # Melhorando a imagem\n",
        "                enhanced_image = enhance(image)\n",
        "\n",
        "                # Salvando a imagem\n",
        "                output_image = img.fromarray(np.uint8(enhanced_image))\n",
        "                output_image.save(os.path.join(dest_image_path, sheet.replace(\"csv\", \"jpg\"))) # cwd/data/images/(nao_)doentes/(nao_)doente_X/IR_XXXXX.jpg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Converte uma matriz de temperaturas em uma matriz de valores de cinza, mantendo proporção\n",
        "def toThermography(temperatureSheet, temperatureMin, temperatureMax):\n",
        "\n",
        "    # Definindo as escalas para conversão\n",
        "    grayMax = 255\n",
        "    grayMin = 0\n",
        "\n",
        "    # Normalização linear aplicada a todas as células do array para converter\n",
        "        # de valores de temperatura a valores de pixel\n",
        "    normalization = lambda i: int((((int(i*1000) - temperatureMin) * (grayMax - grayMin)) / (temperatureMax - temperatureMin)) + grayMin)\n",
        "    vectorized_normalization = np.vectorize(normalization)\n",
        "    image = vectorized_normalization(temperatureSheet)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Remove ruído e equaliza o histograma de uma matriz de pixels\n",
        "def enhance(image):\n",
        "\n",
        "\n",
        "    # Removendo ruído\n",
        "    #denoised = cv2.medianBlur(image.astype(np.uint8),5)\n",
        "    #denoised = cv2.GaussianBlur(image.astype(np.uint8),(5,5),0)\n",
        "    denoised = wiener(image.astype(np.uint8), 5)\n",
        "    rows, cols = image.shape\n",
        "    # Corrigindo glitch wiener em 2 pixels de borda\n",
        "    \n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            if i == 0 or i == 1 or i == len(image)-1 or i == len(image) - 2:\n",
        "                denoised[i][j] = image[i][j]\n",
        "            if j == 0 or j == 1 or j == len(image[0])-1 or j == len(image[0])-2:\n",
        "                denoised[i][j] = image[i][j]\n",
        "    \n",
        "    \n",
        "    # Equalizando histograma\n",
        "    #denoised_equalizedhist = cv2.equalizeHist(denoised.astype(np.uint8))\n",
        "    clahe = cv2.createCLAHE()\n",
        "    denoised_equalizedhist = clahe.apply(denoised.astype(np.uint8))\n",
        "\n",
        "    return denoised_equalizedhist\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Função de interface\n",
        "def preprocess(sub_path):\n",
        "    # Criando a pasta data onde ficarão as imagens e CSVs\n",
        "    if not os.path.exists(img_path):\n",
        "        os.mkdir(img_path)\n",
        "\n",
        "    # Limpando os CSVs\n",
        "    clearCsv(sub_path)\n",
        "    # Gerando as imagens a partir dos CSVs\n",
        "    generateImages()\n",
        "    print(\"Boa execução!!!\")\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "#chamando a função de interface\n",
        "preprocess(sub_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "srshpVydjWgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c162ab-381b-4908-8f76-1cb74921d5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boa execução!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Padding Operation into the non-linear size database\n",
        "\n",
        "def paddingImages():\n",
        "\n",
        "  for paciente in os.listdir(path_doentes):\n",
        "    path_paciente = os.path.join(path_doentes, paciente)\n",
        "    print(path_paciente)\n",
        "    paths_imgs = sorted(glob.glob(os.path.join(path_paciente, \"*.jpg\")))\n",
        "    for i, img_path in enumerate(paths_imgs):\n",
        "      \n",
        "      image = cv2.imread(img_path)\n",
        "      \n",
        "      new_height = 283\n",
        "      new_width = 283\n",
        "      old_height, old_width, channels = image.shape\n",
        "\n",
        "\n",
        "      final_image = np.full((new_height, new_width, channels), (0,0,0), dtype = np.uint8)\n",
        "\n",
        "      x_center = (new_width - old_width) // 2\n",
        "      y_center = (new_height - old_height) // 2\n",
        "\n",
        "      final_image[y_center:y_center+old_height, \n",
        "       x_center:x_center+old_width] = image\n",
        "\n",
        "      new_img_name = img_path.split(\"/\")\n",
        "\n",
        "      os.remove(img_path)\n",
        "\n",
        "      cv2.imwrite(path_paciente + \"/\" + new_img_name[-1], final_image)\n",
        "  \n",
        "  for paciente in os.listdir(path_saudaveis):\n",
        "    path_paciente = os.path.join(path_saudaveis, paciente)\n",
        "    print(path_paciente)\n",
        "    paths_imgs = sorted(glob.glob(os.path.join(path_paciente, \"*.jpg\")))\n",
        "    for i, img_path in enumerate(paths_imgs):\n",
        "      \n",
        "      image = cv2.imread(img_path)\n",
        "      \n",
        "      new_height = 283\n",
        "      new_width = 283\n",
        "      old_height, old_width, channels = image.shape\n",
        "\n",
        "\n",
        "      final_image = np.full((new_height, new_width, channels), (0,0,0), dtype = np.uint8)\n",
        "\n",
        "      x_center = (new_width - old_width) // 2\n",
        "      y_center = (new_height - old_height) // 2\n",
        "\n",
        "      final_image[y_center:y_center+old_height, \n",
        "       x_center:x_center+old_width] = image\n",
        "\n",
        "      new_img_name = img_path.split(\"/\")\n",
        "\n",
        "      os.remove(img_path)\n",
        "\n",
        "      cv2.imwrite(path_paciente + \"/\" + new_img_name[-1], final_image)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0GERooQXnCYu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Ow8tQ9RdjoKaF8pBCpqIInAZhzb4d4M2",
      "authorship_tag": "ABX9TyOzdzg6qsYm27xZql5QmcaO",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}