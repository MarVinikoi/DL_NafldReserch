{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIh81NB/W1EQpDsR0OXTjx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarVinikoi/DL_NafldReserch/blob/main/NAFLD_TCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OIaPFDyXNCPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02da3e3-effc-4a79-b274-a0445118a18b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tcn\n",
            "  Downloading keras_tcn-3.5.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-tcn) (1.23.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-tcn) (2.15.0)\n",
            "Collecting tensorflow-addons (from keras-tcn)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-tcn) (2.15.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->keras-tcn)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-tcn) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow->keras-tcn) (3.2.2)\n",
            "Installing collected packages: typeguard, tensorflow-addons, keras-tcn\n",
            "Successfully installed keras-tcn-3.5.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Collecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.7.1)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.3.2)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.2)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (23.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.5.3)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.2)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2023.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
            "Installing collected packages: livelossplot\n",
            "Successfully installed livelossplot-0.5.5\n",
            "Collecting visualkeras\n",
            "  Downloading visualkeras-0.0.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.23.5)\n",
            "Collecting aggdraw>=1.3.11 (from visualkeras)\n",
            "  Downloading aggdraw-1.3.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.7/993.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.18 visualkeras-0.0.2\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.0-py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.0 colorlog-6.8.0 optuna-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tcn\n",
        "!pip install scikit-learn\n",
        "!pip install livelossplot\n",
        "!pip install visualkeras\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1a_w3SZRNMom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7276b4a4-0ccf-4b3f-91ff-b21e091600c8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/PesquisaNAFLD/Data/NovaBase/\""
      ],
      "metadata": {
        "id": "cBXn2-aSNHz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee97dcc4-b7e5-44df-adaa-c611e31d29c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PesquisaNAFLD/Data/NovaBase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob, os\n",
        "import math\n",
        "import random\n",
        "import optuna\n",
        "from tensorflow.keras import callbacks\n",
        "from tcn import TCN, tcn_full_summary\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "hCkyEa95NJnm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Variáveis Globais\n",
        "\n",
        "path_doentes = \"images/doentes\"\n",
        "path_saudaveis = \"images/nao_doentes\""
      ],
      "metadata": {
        "id": "fQaND1MZNOqW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Carregando as imagens\n",
        "\n",
        "\n",
        "labels_treino = []\n",
        "labels_teste = []\n",
        "labels_val = []\n",
        "\n",
        "\n",
        "vetor_imgs_doe = []\n",
        "vetor_imgs_sau = []\n",
        "vetor_final_imgs = []\n",
        "\n",
        "#Carregando os vetores de imagens e os transformando em séries temporais\n",
        "#Vetor de Doentes\n",
        "for paciente in os.listdir(path_doentes):\n",
        "  path_paciente = os.path.join(path_doentes, paciente)\n",
        "  print(path_paciente)\n",
        "  paths_imgs = sorted(glob.glob(os.path.join(path_paciente, \"*.jpg\")))\n",
        "  for i, img_path in enumerate(paths_imgs):\n",
        "    #Se a imagem for a primeira, última ou do meio, iremos operar sobre ela\n",
        "    if(img_path == paths_imgs[0] or img_path == paths_imgs[-1] or img_path == paths_imgs[round((len(paths_imgs)-1)/2)]):\n",
        "      image = cv2.imread(img_path)\n",
        "      print(f\"image {i} = {img_path}\")\n",
        "\n",
        "      vetor_imgs_doe.append(image)\n",
        "\n",
        "#LABELS --> 0 = DOENTES  ||  1 = SAUDÁVEIS\n",
        "#labels.extend(np.zeros(len(vetor_final_imgs)/timesteps), dtype = \"int32\")\n",
        "\n",
        "#Vetor de Saudáveis\n",
        "for paciente in os.listdir(path_saudaveis):\n",
        "  path_paciente = os.path.join(path_saudaveis, paciente)\n",
        "  paths_imgs = sorted(glob.glob(os.path.join(path_paciente, \"*.jpg\")))\n",
        "  print(path_paciente)\n",
        "  for i, img_path in enumerate(paths_imgs):\n",
        "    #Se a imagem for a primeira, última ou do meio, iremos operar sobre ela\n",
        "    if(img_path == paths_imgs[0] or img_path == paths_imgs[-1] or img_path == paths_imgs[round((len(paths_imgs)-1)/2)]):\n",
        "\n",
        "      image = cv2.imread(img_path)\n",
        "      vetor_imgs_sau.append(image)\n",
        "      print(f\"image {i} = {img_path}\")\n",
        "\n",
        "\n",
        "#LABELS --> 0 = DOENTES  ||  1 = SAUDÁVEIS\n",
        "#labels.extend(np.ones(len(vetor_final_imgs) - len(labels)))\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Len vetor final de doentes: {len(vetor_imgs_doe)}\")\n",
        "print(f\"Len vetor final de saudáveis: {len(vetor_imgs_sau)}\")"
      ],
      "metadata": {
        "id": "l7m-NrnPNQj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9504f0d2-d171-4c3d-f1ba-9fc2ae64e976"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images/doentes/doente_1\n",
            "image 0 = images/doentes/doente_1/table1.jpg\n",
            "image 2 = images/doentes/doente_1/table3.jpg\n",
            "image 4 = images/doentes/doente_1/table5.jpg\n",
            "images/doentes/doente_2\n",
            "image 0 = images/doentes/doente_2/table1.jpg\n",
            "image 2 = images/doentes/doente_2/table3.jpg\n",
            "image 4 = images/doentes/doente_2/table5.jpg\n",
            "images/doentes/doente_3\n",
            "image 0 = images/doentes/doente_3/table1.jpg\n",
            "image 2 = images/doentes/doente_3/table3.jpg\n",
            "image 4 = images/doentes/doente_3/table5.jpg\n",
            "images/doentes/doente_4\n",
            "image 0 = images/doentes/doente_4/table1.jpg\n",
            "image 2 = images/doentes/doente_4/table3.jpg\n",
            "image 4 = images/doentes/doente_4/table5.jpg\n",
            "images/doentes/doente_5\n",
            "image 0 = images/doentes/doente_5/table1.jpg\n",
            "image 2 = images/doentes/doente_5/table3.jpg\n",
            "image 4 = images/doentes/doente_5/table5.jpg\n",
            "images/doentes/doente_6\n",
            "image 0 = images/doentes/doente_6/table1.jpg\n",
            "image 2 = images/doentes/doente_6/table3.jpg\n",
            "image 4 = images/doentes/doente_6/table5.jpg\n",
            "images/doentes/doente_7\n",
            "image 0 = images/doentes/doente_7/table1.jpg\n",
            "image 2 = images/doentes/doente_7/table3.jpg\n",
            "image 4 = images/doentes/doente_7/table5.jpg\n",
            "images/doentes/doente_8\n",
            "image 0 = images/doentes/doente_8/table1.jpg\n",
            "image 2 = images/doentes/doente_8/table3.jpg\n",
            "image 4 = images/doentes/doente_8/table5.jpg\n",
            "images/doentes/doente_9\n",
            "image 0 = images/doentes/doente_9/table1.jpg\n",
            "image 2 = images/doentes/doente_9/table3.jpg\n",
            "image 4 = images/doentes/doente_9/table5.jpg\n",
            "images/doentes/doente_10\n",
            "image 0 = images/doentes/doente_10/table1.jpg\n",
            "image 2 = images/doentes/doente_10/table3.jpg\n",
            "image 4 = images/doentes/doente_10/table5.jpg\n",
            "images/doentes/doente_11\n",
            "image 0 = images/doentes/doente_11/table1.jpg\n",
            "image 2 = images/doentes/doente_11/table3.jpg\n",
            "image 4 = images/doentes/doente_11/table5.jpg\n",
            "images/doentes/doente_12\n",
            "image 0 = images/doentes/doente_12/table1.jpg\n",
            "image 2 = images/doentes/doente_12/table3.jpg\n",
            "image 4 = images/doentes/doente_12/table5.jpg\n",
            "images/doentes/doente_13\n",
            "image 0 = images/doentes/doente_13/table1.jpg\n",
            "image 2 = images/doentes/doente_13/table3.jpg\n",
            "image 4 = images/doentes/doente_13/table5.jpg\n",
            "images/doentes/doente_14\n",
            "image 0 = images/doentes/doente_14/table1.jpg\n",
            "image 2 = images/doentes/doente_14/table3.jpg\n",
            "image 4 = images/doentes/doente_14/table5.jpg\n",
            "images/doentes/doente_15\n",
            "image 0 = images/doentes/doente_15/table1.jpg\n",
            "image 2 = images/doentes/doente_15/table3.jpg\n",
            "image 4 = images/doentes/doente_15/table5.jpg\n",
            "images/doentes/doente_16\n",
            "image 0 = images/doentes/doente_16/table1.jpg\n",
            "image 2 = images/doentes/doente_16/table3.jpg\n",
            "image 4 = images/doentes/doente_16/table5.jpg\n",
            "images/nao_doentes/nao_doente_1\n",
            "image 0 = images/nao_doentes/nao_doente_1/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_1/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_1/table5.jpg\n",
            "images/nao_doentes/nao_doente_2\n",
            "image 0 = images/nao_doentes/nao_doente_2/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_2/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_2/table5.jpg\n",
            "images/nao_doentes/nao_doente_3\n",
            "image 0 = images/nao_doentes/nao_doente_3/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_3/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_3/table5.jpg\n",
            "images/nao_doentes/nao_doente_4\n",
            "image 0 = images/nao_doentes/nao_doente_4/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_4/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_4/table5.jpg\n",
            "images/nao_doentes/nao_doente_5\n",
            "image 0 = images/nao_doentes/nao_doente_5/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_5/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_5/table5.jpg\n",
            "images/nao_doentes/nao_doente_6\n",
            "image 0 = images/nao_doentes/nao_doente_6/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_6/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_6/table5.jpg\n",
            "images/nao_doentes/nao_doente_7\n",
            "image 0 = images/nao_doentes/nao_doente_7/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_7/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_7/table5.jpg\n",
            "images/nao_doentes/nao_doente_8\n",
            "image 0 = images/nao_doentes/nao_doente_8/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_8/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_8/table5.jpg\n",
            "images/nao_doentes/nao_doente_9\n",
            "image 0 = images/nao_doentes/nao_doente_9/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_9/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_9/table5.jpg\n",
            "images/nao_doentes/nao_doente_10\n",
            "image 0 = images/nao_doentes/nao_doente_10/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_10/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_10/table5.jpg\n",
            "images/nao_doentes/nao_doente_11\n",
            "image 0 = images/nao_doentes/nao_doente_11/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_11/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_11/table5.jpg\n",
            "images/nao_doentes/nao_doente_12\n",
            "image 0 = images/nao_doentes/nao_doente_12/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_12/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_12/table5.jpg\n",
            "images/nao_doentes/nao_doente_13\n",
            "image 0 = images/nao_doentes/nao_doente_13/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_13/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_13/table5.jpg\n",
            "images/nao_doentes/nao_doente_14\n",
            "image 0 = images/nao_doentes/nao_doente_14/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_14/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_14/table5.jpg\n",
            "images/nao_doentes/nao_doente_15\n",
            "image 0 = images/nao_doentes/nao_doente_15/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_15/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_15/table5.jpg\n",
            "images/nao_doentes/nao_doente_16\n",
            "image 0 = images/nao_doentes/nao_doente_16/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_16/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_16/table5.jpg\n",
            "images/nao_doentes/nao_doente_17\n",
            "image 0 = images/nao_doentes/nao_doente_17/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_17/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_17/table5.jpg\n",
            "images/nao_doentes/nao_doente_18\n",
            "image 0 = images/nao_doentes/nao_doente_18/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_18/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_18/table5.jpg\n",
            "images/nao_doentes/nao_doente_19\n",
            "image 0 = images/nao_doentes/nao_doente_19/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_19/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_19/table5.jpg\n",
            "images/nao_doentes/nao_doente_20\n",
            "image 0 = images/nao_doentes/nao_doente_20/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_20/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_20/table5.jpg\n",
            "images/nao_doentes/nao_doente_21\n",
            "image 0 = images/nao_doentes/nao_doente_21/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_21/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_21/table5.jpg\n",
            "images/nao_doentes/nao_doente_22\n",
            "image 0 = images/nao_doentes/nao_doente_22/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_22/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_22/table5.jpg\n",
            "images/nao_doentes/nao_doente_23\n",
            "image 0 = images/nao_doentes/nao_doente_23/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_23/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_23/table5.jpg\n",
            "images/nao_doentes/nao_doente_24\n",
            "image 0 = images/nao_doentes/nao_doente_24/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_24/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_24/table5.jpg\n",
            "images/nao_doentes/nao_doente_25\n",
            "image 0 = images/nao_doentes/nao_doente_25/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_25/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_25/table5.jpg\n",
            "images/nao_doentes/nao_doente_26\n",
            "image 0 = images/nao_doentes/nao_doente_26/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_26/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_26/table5.jpg\n",
            "images/nao_doentes/nao_doente_27\n",
            "image 0 = images/nao_doentes/nao_doente_27/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_27/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_27/table5.jpg\n",
            "images/nao_doentes/nao_doente_28\n",
            "image 0 = images/nao_doentes/nao_doente_28/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_28/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_28/table5.jpg\n",
            "images/nao_doentes/nao_doente_29\n",
            "image 0 = images/nao_doentes/nao_doente_29/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_29/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_29/table5.jpg\n",
            "images/nao_doentes/nao_doente_30\n",
            "image 0 = images/nao_doentes/nao_doente_30/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_30/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_30/table5.jpg\n",
            "images/nao_doentes/nao_doente_31\n",
            "image 0 = images/nao_doentes/nao_doente_31/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_31/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_31/table5.jpg\n",
            "images/nao_doentes/nao_doente_32\n",
            "image 0 = images/nao_doentes/nao_doente_32/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_32/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_32/table5.jpg\n",
            "images/nao_doentes/nao_doente_33\n",
            "image 0 = images/nao_doentes/nao_doente_33/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_33/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_33/table5.jpg\n",
            "images/nao_doentes/nao_doente_34\n",
            "image 0 = images/nao_doentes/nao_doente_34/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_34/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_34/table5.jpg\n",
            "images/nao_doentes/nao_doente_35\n",
            "image 0 = images/nao_doentes/nao_doente_35/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_35/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_35/table5.jpg\n",
            "images/nao_doentes/nao_doente_36\n",
            "image 0 = images/nao_doentes/nao_doente_36/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_36/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_36/table5.jpg\n",
            "images/nao_doentes/nao_doente_37\n",
            "image 0 = images/nao_doentes/nao_doente_37/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_37/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_37/table5.jpg\n",
            "images/nao_doentes/nao_doente_38\n",
            "image 0 = images/nao_doentes/nao_doente_38/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_38/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_38/table5.jpg\n",
            "images/nao_doentes/nao_doente_39\n",
            "image 0 = images/nao_doentes/nao_doente_39/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_39/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_39/table5.jpg\n",
            "images/nao_doentes/nao_doente_40\n",
            "image 0 = images/nao_doentes/nao_doente_40/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_40/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_40/table5.jpg\n",
            "images/nao_doentes/nao_doente_41\n",
            "image 0 = images/nao_doentes/nao_doente_41/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_41/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_41/table5.jpg\n",
            "images/nao_doentes/nao_doente_42\n",
            "image 0 = images/nao_doentes/nao_doente_42/table1.jpg\n",
            "image 2 = images/nao_doentes/nao_doente_42/table3.jpg\n",
            "image 4 = images/nao_doentes/nao_doente_42/table5.jpg\n",
            "Len vetor final de doentes: 48\n",
            "Len vetor final de saudáveis: 126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataAugmentation(v_treino_doe : list, v_treino_sau):\n",
        "  labels = []\n",
        "  treino = []\n",
        "  lenght_doe = len(v_treino_doe)\n",
        "  lenght_sau = len(v_treino_sau)\n",
        "  for i in range(lenght_doe):\n",
        "    v_treino_doe.append(cv2.flip(v_treino_doe[i], 0))\n",
        "  for i in range(lenght_doe):\n",
        "    v_treino_doe.append(cv2.flip(v_treino_doe[i], 1))\n",
        "  for i in range(lenght_doe):\n",
        "    v_treino_doe.append(cv2.rotate(v_treino_doe[i], cv2.ROTATE_90_CLOCKWISE))\n",
        "\n",
        "  for i in range(lenght_sau):\n",
        "    v_treino_sau.append(cv2.flip(v_treino_sau[i], 0))\n",
        "  for i in range(lenght_sau):\n",
        "    v_treino_sau.append(cv2.flip(v_treino_sau[i], 1))\n",
        "  for i in range(lenght_sau):\n",
        "    v_treino_sau.append(cv2.rotate(v_treino_sau[i], cv2.ROTATE_90_CLOCKWISE))\n",
        "\n",
        "  labels = [0 for x in range(len(v_treino_doe))]\n",
        "  labels.extend(1 for x in range(len(v_treino_sau)))\n",
        "\n",
        "  treino.extend(v_treino_doe)\n",
        "  treino.extend(v_treino_sau)\n",
        "\n",
        "  return (treino, labels)\n",
        "\n",
        "\n",
        "\n",
        "treino_doe = []\n",
        "treino_sau = []\n",
        "teste = []\n",
        "val = []\n",
        "\n",
        "#Utilizando cerca de 60% das imagens para treino\n",
        "treino_doe.extend(vetor_imgs_doe[:round(len(vetor_imgs_doe)*0.6)])\n",
        "treino_sau.extend(vetor_imgs_sau[:round(len(vetor_imgs_sau)*0.6)])\n",
        "\n",
        "treino, labels_treino = dataAugmentation(treino_doe, treino_sau)\n",
        "\n",
        "#Utilizando cerca de 20% das imagens para teste\n",
        "teste.extend(vetor_imgs_doe[round(len(vetor_imgs_doe)*0.6):round(len(vetor_imgs_doe)*0.8)])\n",
        "labels_teste = [0 for x in range(len(teste))]\n",
        "teste.extend(vetor_imgs_sau[round(len(vetor_imgs_sau)*0.6):round(len(vetor_imgs_sau)*0.8)])\n",
        "labels_teste.extend(1 for x in range(len(teste)-len(labels_teste)))\n",
        "\n",
        "\n",
        "#Utilizando cerca de 20% das imagens para validação\n",
        "val.extend(vetor_imgs_doe[round(len(vetor_imgs_doe)*0.8):])\n",
        "labels_val = [0 for x in range(len(val))]\n",
        "val.extend(vetor_imgs_sau[round(len(vetor_imgs_sau)*0.8):])\n",
        "labels_val.extend(1 for x in range(len(val)-len(labels_val)))\n",
        "\n"
      ],
      "metadata": {
        "id": "WO11aYkTPtUu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conversão das imagens em séries temporais\n",
        "\n",
        "def toTemporal(v_treino, v_teste, v_val, labels_treino, labels_teste, labels_val):\n",
        "  v_final_treino = []\n",
        "  v_final_teste = []\n",
        "  v_final_val = []\n",
        "  labels_final_treino = []\n",
        "  labels_final_teste = []\n",
        "  labels_final_val = []\n",
        "  v_imgs = []\n",
        "\n",
        "  for i, elm in enumerate(v_treino):\n",
        "\n",
        "    r_img, g_img, b_img = cv2.split(elm)\n",
        "\n",
        "    r_img = np.array(r_img)\n",
        "    r_img = np.ndarray.flatten(r_img)\n",
        "\n",
        "    v_imgs.append(r_img)\n",
        "\n",
        "    if len(v_imgs) == 3:\n",
        "      v_final_treino.append((v_imgs[0], v_imgs[1], v_imgs[2]))\n",
        "      v_imgs.clear()\n",
        "\n",
        "\n",
        "  for elm in v_teste:\n",
        "\n",
        "    r_img, g_img, b_img = cv2.split(elm)\n",
        "\n",
        "    r_img = np.array(r_img)\n",
        "    r_img = np.ndarray.flatten(r_img)\n",
        "\n",
        "    v_imgs.append(r_img)\n",
        "\n",
        "    if len(v_imgs) == 3:\n",
        "      v_final_teste.append((v_imgs[0], v_imgs[1], v_imgs[2]))\n",
        "      v_imgs.clear()\n",
        "\n",
        "\n",
        "  for elm in v_val:\n",
        "\n",
        "    r_img, g_img, b_img = cv2.split(elm)\n",
        "\n",
        "    r_img = np.array(r_img)\n",
        "    r_img = np.ndarray.flatten(r_img)\n",
        "\n",
        "    v_imgs.append(r_img)\n",
        "\n",
        "    if len(v_imgs) == 3:\n",
        "      # plot_3d(v_imgs[0], v_imgs[1], v_imgs[2])\n",
        "      v_final_val.append((v_imgs[0], v_imgs[1], v_imgs[2]))\n",
        "      v_imgs.clear()\n",
        "\n",
        "  for i in range(0,len(labels_treino),3):\n",
        "    labels_final_treino.append(labels_treino[i])\n",
        "\n",
        "  for i in range(0,len(labels_teste),3):\n",
        "    labels_final_teste.append(labels_teste[i])\n",
        "\n",
        "  for i in range(0,len(labels_val),3):\n",
        "    labels_final_val.append(labels_val[i])\n",
        "\n",
        "  print(\"Estado dos conjuntos:\")\n",
        "  print(f\"Treino: {len(v_final_treino)} -- Labels: {len(labels_final_treino)}\")\n",
        "  print(f\"Teste: {len(v_final_teste)} -- Labels: {len(labels_final_teste)}\")\n",
        "  print(f\"Val: {len(v_final_val)} -- Labels: {len(labels_final_val)}\")\n",
        "\n",
        "  return (v_final_treino, v_final_teste, v_final_val, labels_final_treino, labels_final_teste, labels_final_val)"
      ],
      "metadata": {
        "id": "Yi5aSCZqMTr-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treino, teste, val, labels_treino, labels_teste, labels_val = toTemporal(treino, teste, val, labels_treino, labels_teste, labels_val)\n",
        "\n",
        "treino = np.array(treino)\n",
        "teste = np.array(teste)\n",
        "val = np.array(val)\n",
        "\n",
        "print(treino.shape)\n",
        "print(teste.shape)\n",
        "print(val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFOPHCvQNMdk",
        "outputId": "daebbde1-65ba-4345-966a-e93a2f701e5a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estado dos conjuntos:\n",
            "Treino: 140 -- Labels: 140\n",
            "Teste: 11 -- Labels: 12\n",
            "Val: 12 -- Labels: 12\n",
            "(140, 3, 80089)\n",
            "(11, 3, 80089)\n",
            "(12, 3, 80089)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Embaralhando os vetores de imagens térmicas\n",
        "\n",
        "random.seed(8528741)\n",
        "\n",
        "zipped_treino = list(zip(treino, labels_treino))\n",
        "zipped_teste = list(zip(teste, labels_teste))\n",
        "zipped_val = list(zip(val, labels_val))\n",
        "\n",
        "random.shuffle(zipped_treino)\n",
        "random.shuffle(zipped_teste)\n",
        "random.shuffle(zipped_val)\n",
        "\n",
        "treino, labels_treino = zip(*zipped_treino)\n",
        "teste, labels_teste = zip(*zipped_teste)\n",
        "val, labels_val = zip(*zipped_val)\n",
        "\n",
        "treino = np.array(treino)\n",
        "teste = np.array(teste)\n",
        "val = np.array(val)\n",
        "labels_treino = np.array(labels_treino)\n",
        "labels_teste = np.array(labels_teste)\n",
        "labels_val = np.array(labels_val)"
      ],
      "metadata": {
        "id": "MUviBhwjN4Cu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Otimização com Optuna\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score, f1_score\n",
        "\n",
        "#Acumuladores de Métricas\n",
        "recall = []\n",
        "prec = []\n",
        "f1 = []\n",
        "matrizes = []\n",
        "\n",
        "n_iter = 10\n",
        "\n",
        "callback_funcs = []\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "  tcn_nbfilters = trial.suggest_categorical(\"nb_filters\", [16, 32, 64, 128])\n",
        "  tcn_kernelsize = trial.suggest_int(\"kernel_size\", 3, 9, log=True)\n",
        "  tcn_nbstacks = trial.suggest_int(\"nb_stacks\", 1, 3, log=True)\n",
        "  tcn_kernelinit = trial.suggest_categorical(\"kernel_initializer\", [\"he_normal\", \"glorot_uniform\"])\n",
        "  #tcn_dropout = trial.suggest_categorical(\"dropout_rate\", [0.001, 0.01, 0.1])\n",
        "\n",
        "  model = Sequential([\n",
        "      TCN(\n",
        "          nb_filters = tcn_nbfilters, kernel_size = tcn_kernelsize, nb_stacks = tcn_nbstacks,\n",
        "          kernel_initializer = tcn_kernelinit, dilations = (1,2,4,8,16,32,64)\n",
        "          ),\n",
        "      tf.keras.layers.Dense(units=1,activation=\"sigmoid\")\n",
        "\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss = tf.losses.BinaryFocalCrossentropy(), metrics = [\"accuracy\"])\n",
        "  print(\"\\n\\n\")\n",
        "\n",
        "  hist = model.fit(treino, labels_treino, validation_data=(val, labels_val), epochs=20, callbacks = callback_funcs)\n",
        "\n",
        "  y_pred = model.predict(teste)\n",
        "  for i, elm in enumerate(y_pred):\n",
        "    y_pred[i] = np.round(elm)\n",
        "  y_true = labels_teste\n",
        "\n",
        "  recall.append(recall_score(y_true, y_pred, average='weighted'))\n",
        "  prec.append(precision_score(y_true, y_pred, average='weighted'))\n",
        "  f1.append(f1_score(y_true, y_pred, average='weighted'))\n",
        "  matrix = confusion_matrix(y_true, y_pred)\n",
        "  matrizes.append(matrix)\n",
        "\n",
        "  return precision_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=n_iter)\n",
        "\n",
        "\n",
        "recall_media = np.asarray(recall).mean(axis=0)\n",
        "prec_media = np.asarray(prec).mean(axis=0)\n",
        "f1_media = np.asarray(f1).mean(axis=0)\n",
        "\n",
        "#calculando os desvios das execuções\n",
        "recall_std = np.asarray(recall).std(axis=0)\n",
        "prec_std = np.asarray(prec).std(axis=0)\n",
        "f1_std = np.asarray(f1).std(axis=0)\n",
        "\n",
        "#sns.heatmap(matrix, cmap='Blues', annot=True)\n",
        "\n",
        "print (\"Recall: \" + str(recall_media) + \" +- \" + str(recall_std))\n",
        "print (\"Precisão: \" + str(prec_media) + \" +- \" + str(prec_std))\n",
        "print (\"F1: \" + str(f1_media) + \" +- \" + str(f1_std))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1uTo47nN-iD",
        "outputId": "9a204f1b-eaa9-4d22-8422-4babbbe62f24"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-18 16:43:14,043] A new study created in memory with name: no-name-2384227a-01aa-456e-9dd0-ad7c4f8ad321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 59s 11s/step - loss: 3645.1821 - accuracy: 0.5214 - val_loss: 3028.1985 - val_accuracy: 0.6667\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 2096.8250 - accuracy: 0.5214 - val_loss: 36.5858 - val_accuracy: 0.8333\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 1s 142ms/step - loss: 795.2663 - accuracy: 0.7000 - val_loss: 825.3898 - val_accuracy: 0.6667\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 1s 162ms/step - loss: 372.6501 - accuracy: 0.6643 - val_loss: 344.8022 - val_accuracy: 0.7500\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 129.6324 - accuracy: 0.7571 - val_loss: 40.5321 - val_accuracy: 0.8333\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 1s 144ms/step - loss: 112.2299 - accuracy: 0.8071 - val_loss: 35.6304 - val_accuracy: 0.9167\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 1s 161ms/step - loss: 68.1023 - accuracy: 0.8000 - val_loss: 104.2834 - val_accuracy: 0.7500\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 32.0516 - accuracy: 0.8429 - val_loss: 42.1859 - val_accuracy: 0.6667\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 47.5483 - accuracy: 0.7643 - val_loss: 103.0091 - val_accuracy: 0.7500\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 20.4119 - accuracy: 0.8286 - val_loss: 101.8476 - val_accuracy: 0.7500\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 49.6715 - accuracy: 0.8429 - val_loss: 80.5791 - val_accuracy: 0.7500\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 26.1270 - accuracy: 0.8571 - val_loss: 62.5572 - val_accuracy: 0.8333\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 19.1692 - accuracy: 0.9286 - val_loss: 34.4892 - val_accuracy: 0.8333\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 20.2991 - accuracy: 0.8929 - val_loss: 80.4857 - val_accuracy: 0.7500\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 9.5551 - accuracy: 0.9286 - val_loss: 54.9064 - val_accuracy: 0.7500\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 1.6853 - accuracy: 0.9714 - val_loss: 106.9412 - val_accuracy: 0.6667\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 3.2569 - accuracy: 0.9571 - val_loss: 64.0652 - val_accuracy: 0.7500\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.8849 - accuracy: 0.9643 - val_loss: 79.5038 - val_accuracy: 0.6667\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.9079 - accuracy: 0.9786 - val_loss: 89.5602 - val_accuracy: 0.6667\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.3245 - accuracy: 0.9929 - val_loss: 75.5996 - val_accuracy: 0.6667\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 1s 163ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 62.8783 - val_accuracy: 0.6667\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.3427 - accuracy: 0.9786 - val_loss: 72.1699 - val_accuracy: 0.6667\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 108.3882 - val_accuracy: 0.7500\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 1s 160ms/step - loss: 0.3742 - accuracy: 0.9786 - val_loss: 62.3850 - val_accuracy: 0.7500\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 1.4346 - accuracy: 0.9714 - val_loss: 64.7480 - val_accuracy: 0.7500\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 1s 142ms/step - loss: 1.0918 - accuracy: 0.9714 - val_loss: 98.1567 - val_accuracy: 0.7500\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 1s 158ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 81.6886 - val_accuracy: 0.8333\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 75.8776 - val_accuracy: 0.8333\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 74.5142 - val_accuracy: 0.7500\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 73.9851 - val_accuracy: 0.7500\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-18 16:44:44,983] Trial 0 finished with value: 0.9191919191919191 and parameters: {'nb_filters': 64, 'kernel_size': 7, 'nb_stacks': 2, 'kernel_initializer': 'glorot_uniform'}. Best is trial 0 with value: 0.9191919191919191.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 17s 777ms/step - loss: 3114.4287 - accuracy: 0.5357 - val_loss: 2589.6726 - val_accuracy: 0.6667\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 1414.2028 - accuracy: 0.5714 - val_loss: 1213.8068 - val_accuracy: 0.6667\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 690.5637 - accuracy: 0.6714 - val_loss: 1305.0360 - val_accuracy: 0.6667\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 520.1569 - accuracy: 0.7429 - val_loss: 93.8541 - val_accuracy: 0.7500\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 202.3175 - accuracy: 0.8500 - val_loss: 375.3274 - val_accuracy: 0.6667\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 127.0914 - accuracy: 0.8643 - val_loss: 250.3722 - val_accuracy: 0.6667\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 81ms/step - loss: 81.9279 - accuracy: 0.8786 - val_loss: 345.3737 - val_accuracy: 0.7500\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 82ms/step - loss: 50.3561 - accuracy: 0.8786 - val_loss: 266.8172 - val_accuracy: 0.8333\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 38.4572 - accuracy: 0.9286 - val_loss: 183.6252 - val_accuracy: 0.8333\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 80ms/step - loss: 66.7285 - accuracy: 0.8857 - val_loss: 302.3503 - val_accuracy: 0.7500\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 43.6853 - accuracy: 0.9357 - val_loss: 741.2422 - val_accuracy: 0.6667\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 37.8410 - accuracy: 0.9500 - val_loss: 279.3129 - val_accuracy: 0.7500\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 14.9314 - accuracy: 0.9500 - val_loss: 414.3377 - val_accuracy: 0.7500\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 21.7446 - accuracy: 0.9714 - val_loss: 359.5942 - val_accuracy: 0.7500\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 86ms/step - loss: 29.5295 - accuracy: 0.9571 - val_loss: 335.1537 - val_accuracy: 0.7500\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 83ms/step - loss: 39.6001 - accuracy: 0.9071 - val_loss: 765.9035 - val_accuracy: 0.6667\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 84ms/step - loss: 125.4787 - accuracy: 0.8500 - val_loss: 575.5930 - val_accuracy: 0.7500\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 82.6388 - accuracy: 0.9143 - val_loss: 252.5132 - val_accuracy: 0.8333\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 246.4747 - accuracy: 0.7643 - val_loss: 246.6775 - val_accuracy: 0.8333\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 575.7035 - accuracy: 0.7143 - val_loss: 1306.0778 - val_accuracy: 0.7500\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 130.1809 - accuracy: 0.9214 - val_loss: 295.2679 - val_accuracy: 0.8333\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 38.0039 - accuracy: 0.9357 - val_loss: 1168.1041 - val_accuracy: 0.6667\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 111.1986 - accuracy: 0.8786 - val_loss: 386.4934 - val_accuracy: 0.7500\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 15.5676 - accuracy: 0.9786 - val_loss: 1790.1240 - val_accuracy: 0.6667\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 79ms/step - loss: 222.8250 - accuracy: 0.8857 - val_loss: 405.3717 - val_accuracy: 0.7500\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 85ms/step - loss: 133.5867 - accuracy: 0.8929 - val_loss: 1159.7606 - val_accuracy: 0.6667\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 111.9169 - accuracy: 0.8714 - val_loss: 356.0420 - val_accuracy: 0.7500\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 75.4192 - accuracy: 0.9000 - val_loss: 1103.8812 - val_accuracy: 0.6667\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 87ms/step - loss: 87.9745 - accuracy: 0.9286 - val_loss: 312.3902 - val_accuracy: 0.7500\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 91ms/step - loss: 59.8035 - accuracy: 0.9357 - val_loss: 550.5798 - val_accuracy: 0.8333\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-18 16:45:35,634] Trial 1 finished with value: 0.9191919191919191 and parameters: {'nb_filters': 32, 'kernel_size': 5, 'nb_stacks': 2, 'kernel_initializer': 'he_normal'}. Best is trial 0 with value: 0.9191919191919191.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 11s 588ms/step - loss: 1198.8636 - accuracy: 0.6357 - val_loss: 1304.9111 - val_accuracy: 0.3333\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 1032.1748 - accuracy: 0.4929 - val_loss: 812.1269 - val_accuracy: 0.7500\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 554.7206 - accuracy: 0.6429 - val_loss: 228.7291 - val_accuracy: 0.8333\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 252.9581 - accuracy: 0.7357 - val_loss: 451.9669 - val_accuracy: 0.7500\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 165.7841 - accuracy: 0.7857 - val_loss: 249.1276 - val_accuracy: 0.9167\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 130.6344 - accuracy: 0.8500 - val_loss: 181.3397 - val_accuracy: 0.9167\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 50.7921 - accuracy: 0.8357 - val_loss: 532.4296 - val_accuracy: 0.6667\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 212.6131 - accuracy: 0.8286 - val_loss: 189.1780 - val_accuracy: 0.8333\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 125.0886 - accuracy: 0.8214 - val_loss: 497.6747 - val_accuracy: 0.6667\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 73.7709 - accuracy: 0.8786 - val_loss: 110.1253 - val_accuracy: 0.8333\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 69.4702 - accuracy: 0.8786 - val_loss: 650.7031 - val_accuracy: 0.6667\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 93.1848 - accuracy: 0.8929 - val_loss: 187.3826 - val_accuracy: 0.8333\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 131.7829 - accuracy: 0.8071 - val_loss: 618.3967 - val_accuracy: 0.6667\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 89.6857 - accuracy: 0.8643 - val_loss: 276.8116 - val_accuracy: 0.7500\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 60.1319 - accuracy: 0.8786 - val_loss: 410.7130 - val_accuracy: 0.6667\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 14.7024 - accuracy: 0.9429 - val_loss: 261.9920 - val_accuracy: 0.7500\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 22.3256 - accuracy: 0.9429 - val_loss: 535.6562 - val_accuracy: 0.7500\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 26.8832 - accuracy: 0.9500 - val_loss: 235.5430 - val_accuracy: 0.7500\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 13.2242 - accuracy: 0.9429 - val_loss: 397.6630 - val_accuracy: 0.6667\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.5629 - accuracy: 0.9857 - val_loss: 545.0157 - val_accuracy: 0.6667\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 1.1647 - accuracy: 0.9857 - val_loss: 407.7567 - val_accuracy: 0.6667\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 295.8729 - val_accuracy: 0.7500\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 72ms/step - loss: 1.0013 - accuracy: 0.9929 - val_loss: 299.7420 - val_accuracy: 0.6667\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 326.9921 - val_accuracy: 0.6667\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 0.1622 - accuracy: 0.9929 - val_loss: 395.7311 - val_accuracy: 0.6667\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 461.1605 - val_accuracy: 0.6667\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 500.9497 - val_accuracy: 0.6667\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 5.3169e-10 - accuracy: 1.0000 - val_loss: 525.0121 - val_accuracy: 0.6667\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 0.6836 - accuracy: 0.9857 - val_loss: 341.6966 - val_accuracy: 0.7500\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 0.5608 - accuracy: 0.9786 - val_loss: 391.5185 - val_accuracy: 0.7500\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-18 16:46:02,517] Trial 2 finished with value: 1.0 and parameters: {'nb_filters': 16, 'kernel_size': 5, 'nb_stacks': 1, 'kernel_initializer': 'he_normal'}. Best is trial 2 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 14s 335ms/step - loss: 2315.0928 - accuracy: 0.4786 - val_loss: 404.1917 - val_accuracy: 0.6667\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 1s 115ms/step - loss: 1269.5387 - accuracy: 0.5286 - val_loss: 4109.3618 - val_accuracy: 0.6667\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 1s 114ms/step - loss: 2015.9447 - accuracy: 0.7286 - val_loss: 415.1068 - val_accuracy: 0.6667\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 1s 118ms/step - loss: 810.7759 - accuracy: 0.6714 - val_loss: 1323.5098 - val_accuracy: 0.6667\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 1s 112ms/step - loss: 453.8972 - accuracy: 0.7571 - val_loss: 73.0450 - val_accuracy: 0.8333\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 1s 114ms/step - loss: 173.5879 - accuracy: 0.8500 - val_loss: 330.9795 - val_accuracy: 0.8333\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 1s 112ms/step - loss: 60.0804 - accuracy: 0.8643 - val_loss: 255.4371 - val_accuracy: 0.7500\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 1s 115ms/step - loss: 102.2501 - accuracy: 0.8286 - val_loss: 706.6937 - val_accuracy: 0.6667\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 89.7213 - accuracy: 0.8357 - val_loss: 750.3606 - val_accuracy: 0.6667\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 126.4499 - accuracy: 0.8714 - val_loss: 163.4058 - val_accuracy: 0.7500\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 1s 126ms/step - loss: 92.7289 - accuracy: 0.8786 - val_loss: 816.3233 - val_accuracy: 0.6667\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 1s 125ms/step - loss: 87.3238 - accuracy: 0.8857 - val_loss: 263.4108 - val_accuracy: 0.8333\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 1s 124ms/step - loss: 31.5548 - accuracy: 0.9143 - val_loss: 446.0969 - val_accuracy: 0.7500\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 1s 124ms/step - loss: 1.0204 - accuracy: 0.9857 - val_loss: 288.2356 - val_accuracy: 0.7500\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 1s 127ms/step - loss: 5.9135 - accuracy: 0.9786 - val_loss: 289.2621 - val_accuracy: 0.7500\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 1s 117ms/step - loss: 3.8571 - accuracy: 0.9857 - val_loss: 289.3394 - val_accuracy: 0.7500\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 1s 113ms/step - loss: 0.8829 - accuracy: 0.9929 - val_loss: 267.8007 - val_accuracy: 0.7500\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 4.0030 - accuracy: 0.9714 - val_loss: 338.6143 - val_accuracy: 0.6667\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 1s 115ms/step - loss: 18.6084 - accuracy: 0.9714 - val_loss: 402.6621 - val_accuracy: 0.6667\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 219.2334 - val_accuracy: 0.8333\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 1s 118ms/step - loss: 11.8800 - accuracy: 0.9500 - val_loss: 357.7369 - val_accuracy: 0.7500\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 1s 118ms/step - loss: 14.5500 - accuracy: 0.9643 - val_loss: 315.4234 - val_accuracy: 0.7500\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 1s 116ms/step - loss: 2.6364 - accuracy: 0.9714 - val_loss: 327.4027 - val_accuracy: 0.7500\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 1s 114ms/step - loss: 6.0061 - accuracy: 0.9857 - val_loss: 398.7993 - val_accuracy: 0.6667\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 1s 113ms/step - loss: 0.6549 - accuracy: 0.9929 - val_loss: 349.8722 - val_accuracy: 0.7500\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 1s 115ms/step - loss: 6.0199 - accuracy: 0.9857 - val_loss: 418.5999 - val_accuracy: 0.7500\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 1s 113ms/step - loss: 3.5062 - accuracy: 0.9786 - val_loss: 257.4341 - val_accuracy: 0.7500\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 1s 114ms/step - loss: 26.9788 - accuracy: 0.9429 - val_loss: 371.4967 - val_accuracy: 0.7500\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 1s 112ms/step - loss: 69.8828 - accuracy: 0.8929 - val_loss: 798.8676 - val_accuracy: 0.6667\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 1s 113ms/step - loss: 47.4865 - accuracy: 0.9143 - val_loss: 479.8133 - val_accuracy: 0.8333\n",
            "1/1 [==============================] - 1s 717ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-18 16:46:52,340] Trial 3 finished with value: 1.0 and parameters: {'nb_filters': 64, 'kernel_size': 6, 'nb_stacks': 2, 'kernel_initializer': 'glorot_uniform'}. Best is trial 2 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch 1/30\n",
            "5/5 [==============================] - 10s 605ms/step - loss: 8415.5742 - accuracy: 0.4786 - val_loss: 6333.0063 - val_accuracy: 0.6667\n",
            "Epoch 2/30\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 5619.7373 - accuracy: 0.7214 - val_loss: 12.0524 - val_accuracy: 0.9167\n",
            "Epoch 3/30\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 1283.2816 - accuracy: 0.6357 - val_loss: 2114.6331 - val_accuracy: 0.6667\n",
            "Epoch 4/30\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 1101.3065 - accuracy: 0.6286 - val_loss: 426.2914 - val_accuracy: 0.7500\n",
            "Epoch 5/30\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 550.3024 - accuracy: 0.7929 - val_loss: 182.4148 - val_accuracy: 0.9167\n",
            "Epoch 6/30\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 270.5333 - accuracy: 0.8071 - val_loss: 242.9438 - val_accuracy: 0.8333\n",
            "Epoch 7/30\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 244.2899 - accuracy: 0.8500 - val_loss: 288.0920 - val_accuracy: 0.7500\n",
            "Epoch 8/30\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 53.3831 - accuracy: 0.8643 - val_loss: 472.8275 - val_accuracy: 0.6667\n",
            "Epoch 9/30\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 46.3085 - accuracy: 0.8714 - val_loss: 678.4568 - val_accuracy: 0.6667\n",
            "Epoch 10/30\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 98.7162 - accuracy: 0.8643 - val_loss: 220.5529 - val_accuracy: 0.7500\n",
            "Epoch 11/30\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 41.7724 - accuracy: 0.9286 - val_loss: 752.7561 - val_accuracy: 0.6667\n",
            "Epoch 12/30\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 52.8248 - accuracy: 0.8857 - val_loss: 552.0534 - val_accuracy: 0.7500\n",
            "Epoch 13/30\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 44.8410 - accuracy: 0.9000 - val_loss: 180.8437 - val_accuracy: 0.8333\n",
            "Epoch 14/30\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 64.3472 - accuracy: 0.8857 - val_loss: 573.1976 - val_accuracy: 0.6667\n",
            "Epoch 15/30\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 44.5194 - accuracy: 0.9357 - val_loss: 249.0984 - val_accuracy: 0.7500\n",
            "Epoch 16/30\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 42.6226 - accuracy: 0.9071 - val_loss: 669.3061 - val_accuracy: 0.6667\n",
            "Epoch 17/30\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 29.4513 - accuracy: 0.9357 - val_loss: 344.0039 - val_accuracy: 0.7500\n",
            "Epoch 18/30\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 28.3338 - accuracy: 0.9429 - val_loss: 414.6218 - val_accuracy: 0.7500\n",
            "Epoch 19/30\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 4.5696 - accuracy: 0.9857 - val_loss: 478.4476 - val_accuracy: 0.8333\n",
            "Epoch 20/30\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 484.7415 - val_accuracy: 0.8333\n",
            "Epoch 21/30\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 490.7788 - val_accuracy: 0.8333\n",
            "Epoch 22/30\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 4.2369e-11 - accuracy: 1.0000 - val_loss: 499.0104 - val_accuracy: 0.7500\n",
            "Epoch 23/30\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.0377 - accuracy: 0.9929 - val_loss: 471.0445 - val_accuracy: 0.7500\n",
            "Epoch 24/30\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 433.6817 - val_accuracy: 0.7500\n",
            "Epoch 25/30\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.1652 - accuracy: 0.9929 - val_loss: 501.1718 - val_accuracy: 0.7500\n",
            "Epoch 26/30\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 549.1555 - val_accuracy: 0.7500\n",
            "Epoch 27/30\n",
            "5/5 [==============================] - 0s 101ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 571.3417 - val_accuracy: 0.7500\n",
            "Epoch 28/30\n",
            "5/5 [==============================] - 0s 105ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 583.6478 - val_accuracy: 0.7500\n",
            "Epoch 29/30\n",
            "5/5 [==============================] - 1s 110ms/step - loss: 0.7007 - accuracy: 0.9929 - val_loss: 507.8999 - val_accuracy: 0.7500\n",
            "Epoch 30/30\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 456.5508 - val_accuracy: 0.7500\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-18 16:47:17,945] Trial 4 finished with value: 0.9191919191919191 and parameters: {'nb_filters': 128, 'kernel_size': 3, 'nb_stacks': 1, 'kernel_initializer': 'glorot_uniform'}. Best is trial 2 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 0.9454545454545455 +- 0.04453617714151235\n",
            "Precisão: 0.9515151515151515 +- 0.039587713014677665\n",
            "F1: 0.9416042780748664 +- 0.04767990729267789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Teste com os melhores hiperparâmetros obtidos na etapa anterior\n",
        "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score, f1_score, accuracy_score\n",
        "from livelossplot import PlotLossesKeras\n",
        "\n",
        "holdout_iter = 5\n",
        "recall = []\n",
        "accuracy = []\n",
        "prec = []\n",
        "f1 = []\n",
        "matrizes = []\n",
        "\n",
        "\n",
        "callback_funcs = []\n",
        "\n",
        "for _ in range(holdout_iter):\n",
        "\n",
        "  model = Sequential([\n",
        "      TCN(\n",
        "          nb_filters = 16, kernel_size = 5, nb_stacks = 1,\n",
        "          kernel_initializer = 'he_normal', dilations = (1,2,4,8,16,32,64)\n",
        "          ),\n",
        "      tf.keras.layers.Dense(units=1,activation=\"sigmoid\")\n",
        "\n",
        "  ])\n",
        "\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss = tf.losses.BinaryFocalCrossentropy(), metrics = [\"accuracy\"])\n",
        "\n",
        "  hist = model.fit(treino, labels_treino, validation_data=(val, labels_val), epochs=20, callbacks = callback_funcs)\n",
        "\n",
        "  y_pred = model.predict(teste)\n",
        "  for i, elm in enumerate(y_pred):\n",
        "    y_pred[i] = np.round(elm)\n",
        "  y_true = labels_teste\n",
        "\n",
        "  recall.append(recall_score(y_true, y_pred, average='weighted'))\n",
        "  prec.append(precision_score(y_true, y_pred, average='weighted'))\n",
        "  f1.append(f1_score(y_true, y_pred, average='weighted'))\n",
        "  accuracy.append(accuracy_score(y_true, y_pred))\n",
        "  matrix = confusion_matrix(y_true, y_pred)\n",
        "  matrizes.append(matrix)\n",
        "\n",
        "recall_media = np.asarray(recall).mean(axis=0)\n",
        "prec_media = np.asarray(prec).mean(axis=0)\n",
        "f1_media = np.asarray(f1).mean(axis=0)\n",
        "accuracy_media = np.asarray(accuracy).mean(axis=0)\n",
        "\n",
        "#calculando os desvios das execuções\n",
        "recall_std = np.asarray(recall).std(axis=0)\n",
        "prec_std = np.asarray(prec).std(axis=0)\n",
        "f1_std = np.asarray(f1).std(axis=0)\n",
        "accuracy_std = np.asarray(accuracy).std(axis=0)\n",
        "\n",
        "\n",
        "print (\"Acurácia: \" + str(accuracy_media) + \" +- \" + str(accuracy_std))\n",
        "print (\"Recall: \" + str(recall_media) + \" +- \" + str(recall_std))\n",
        "print (\"Precisão: \" + str(prec_media) + \" +- \" + str(prec_std))\n",
        "print (\"F1: \" + str(f1_media) + \" +- \" + str(f1_std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y3rUVVF8r3B",
        "outputId": "2fb7b733-669e-461d-934e-5050f5a5c48f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "5/5 [==============================] - 6s 210ms/step - loss: 1676.1151 - accuracy: 0.3857 - val_loss: 1735.2958 - val_accuracy: 0.6667\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 946.5355 - accuracy: 0.5929 - val_loss: 61.0603 - val_accuracy: 0.9167\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 390.1703 - accuracy: 0.7429 - val_loss: 57.2763 - val_accuracy: 0.8333\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 278.7560 - accuracy: 0.7000 - val_loss: 338.1283 - val_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 248.8253 - accuracy: 0.8000 - val_loss: 22.8721 - val_accuracy: 0.9167\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 204.8860 - accuracy: 0.8000 - val_loss: 254.4404 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 102.7372 - accuracy: 0.8500 - val_loss: 53.1019 - val_accuracy: 0.8333\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 47.9603 - accuracy: 0.9143 - val_loss: 108.4902 - val_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 19.9490 - accuracy: 0.9214 - val_loss: 228.0507 - val_accuracy: 0.6667\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 19.8851 - accuracy: 0.9571 - val_loss: 212.2715 - val_accuracy: 0.6667\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 7.7878 - accuracy: 0.9571 - val_loss: 159.2618 - val_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 5.4375 - accuracy: 0.9643 - val_loss: 212.7920 - val_accuracy: 0.8333\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 4.0444 - accuracy: 0.9714 - val_loss: 179.1010 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 0.7494 - accuracy: 0.9786 - val_loss: 163.8666 - val_accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 4.4149 - accuracy: 0.9857 - val_loss: 179.7240 - val_accuracy: 0.8333\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.3957 - accuracy: 0.9929 - val_loss: 155.6006 - val_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 5.5784 - accuracy: 0.9786 - val_loss: 161.9746 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 1.7767 - accuracy: 0.9929 - val_loss: 267.2460 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 70ms/step - loss: 10.6201 - accuracy: 0.9714 - val_loss: 163.8822 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 137.7792 - val_accuracy: 0.7500\n",
            "1/1 [==============================] - 1s 565ms/step\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 6s 207ms/step - loss: 705.4592 - accuracy: 0.5786 - val_loss: 319.6365 - val_accuracy: 0.6667\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 192.1826 - accuracy: 0.6000 - val_loss: 278.0770 - val_accuracy: 0.6667\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 89.6380 - accuracy: 0.8143 - val_loss: 131.5060 - val_accuracy: 0.6667\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 124.6943 - accuracy: 0.7000 - val_loss: 210.3677 - val_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 73.9132 - accuracy: 0.8286 - val_loss: 260.4489 - val_accuracy: 0.6667\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 34.8823 - accuracy: 0.8714 - val_loss: 254.6225 - val_accuracy: 0.6667\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 26.1426 - accuracy: 0.8786 - val_loss: 472.9138 - val_accuracy: 0.6667\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 60.5730 - accuracy: 0.8071 - val_loss: 325.0353 - val_accuracy: 0.6667\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 34.4151 - accuracy: 0.8643 - val_loss: 261.5634 - val_accuracy: 0.5000\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 21.6922 - accuracy: 0.8571 - val_loss: 450.5322 - val_accuracy: 0.6667\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 24.3092 - accuracy: 0.8857 - val_loss: 275.0311 - val_accuracy: 0.6667\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 7.4121 - accuracy: 0.9643 - val_loss: 325.1105 - val_accuracy: 0.7500\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 57ms/step - loss: 5.0615 - accuracy: 0.9714 - val_loss: 261.0131 - val_accuracy: 0.6667\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 1.2404 - accuracy: 0.9857 - val_loss: 278.8058 - val_accuracy: 0.6667\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 2.9516 - accuracy: 0.9857 - val_loss: 336.6083 - val_accuracy: 0.6667\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 5.1510 - accuracy: 0.9714 - val_loss: 229.1532 - val_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 3.3868 - accuracy: 0.9643 - val_loss: 257.7356 - val_accuracy: 0.5833\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 10.7843 - accuracy: 0.9500 - val_loss: 221.3793 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 0.5017 - accuracy: 0.9786 - val_loss: 286.2737 - val_accuracy: 0.6667\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 65ms/step - loss: 0.8830 - accuracy: 0.9929 - val_loss: 291.5834 - val_accuracy: 0.6667\n",
            "1/1 [==============================] - 1s 572ms/step\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 7s 214ms/step - loss: 1652.2185 - accuracy: 0.5643 - val_loss: 1028.1980 - val_accuracy: 0.6667\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 331.3407 - accuracy: 0.6714 - val_loss: 52.5911 - val_accuracy: 0.9167\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 122.3177 - accuracy: 0.7643 - val_loss: 68.3774 - val_accuracy: 0.9167\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 87.5280 - accuracy: 0.8071 - val_loss: 464.3048 - val_accuracy: 0.6667\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 145.7918 - accuracy: 0.7714 - val_loss: 79.7016 - val_accuracy: 0.6667\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 163.5992 - accuracy: 0.7571 - val_loss: 445.2306 - val_accuracy: 0.6667\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 96.4379 - accuracy: 0.8000 - val_loss: 247.6354 - val_accuracy: 0.8333\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 32.9766 - accuracy: 0.8929 - val_loss: 218.7411 - val_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 26.0293 - accuracy: 0.9071 - val_loss: 230.9166 - val_accuracy: 0.8333\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 18.1194 - accuracy: 0.9286 - val_loss: 260.0009 - val_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 17.9630 - accuracy: 0.9429 - val_loss: 270.2876 - val_accuracy: 0.8333\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 15.2942 - accuracy: 0.9429 - val_loss: 108.8636 - val_accuracy: 0.6667\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 9.5489 - accuracy: 0.9286 - val_loss: 172.1855 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 13.1654 - accuracy: 0.9571 - val_loss: 92.0853 - val_accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 5.6087 - accuracy: 0.9429 - val_loss: 291.1399 - val_accuracy: 0.6667\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 63ms/step - loss: 45.4038 - accuracy: 0.8000 - val_loss: 242.0920 - val_accuracy: 0.6667\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 72.7206 - accuracy: 0.7857 - val_loss: 86.6076 - val_accuracy: 0.9167\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 150.6862 - accuracy: 0.8000 - val_loss: 216.7891 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 30.2477 - accuracy: 0.8786 - val_loss: 92.1001 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 71ms/step - loss: 19.9598 - accuracy: 0.9214 - val_loss: 74.6197 - val_accuracy: 0.8333\n",
            "1/1 [==============================] - 1s 585ms/step\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 8s 216ms/step - loss: 1091.2288 - accuracy: 0.6214 - val_loss: 1485.5895 - val_accuracy: 0.6667\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 64ms/step - loss: 1416.7727 - accuracy: 0.5143 - val_loss: 1985.9930 - val_accuracy: 0.6667\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 1275.5580 - accuracy: 0.7214 - val_loss: 129.7357 - val_accuracy: 0.8333\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 544.2487 - accuracy: 0.6571 - val_loss: 637.9067 - val_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 304.3071 - accuracy: 0.7714 - val_loss: 678.4026 - val_accuracy: 0.7500\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 217.6641 - accuracy: 0.8143 - val_loss: 282.4586 - val_accuracy: 0.8333\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 308.9356 - accuracy: 0.7643 - val_loss: 1029.8177 - val_accuracy: 0.7500\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 134.3493 - accuracy: 0.9071 - val_loss: 627.2596 - val_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 49.0732 - accuracy: 0.9143 - val_loss: 1137.2413 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 66ms/step - loss: 91.5497 - accuracy: 0.9071 - val_loss: 696.2381 - val_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 56.2214 - accuracy: 0.9214 - val_loss: 1235.2052 - val_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 66.1538 - accuracy: 0.9143 - val_loss: 632.0024 - val_accuracy: 0.7500\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 14.9890 - accuracy: 0.9714 - val_loss: 1095.1344 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 37.7955 - accuracy: 0.9286 - val_loss: 579.4656 - val_accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 69ms/step - loss: 65.9891 - accuracy: 0.9143 - val_loss: 1200.9237 - val_accuracy: 0.6667\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 137.8027 - accuracy: 0.8857 - val_loss: 396.3987 - val_accuracy: 0.6667\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 76ms/step - loss: 143.4518 - accuracy: 0.8643 - val_loss: 1257.5695 - val_accuracy: 0.6667\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 48.1041 - accuracy: 0.9214 - val_loss: 818.6750 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 78ms/step - loss: 23.9035 - accuracy: 0.9571 - val_loss: 903.2259 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 75ms/step - loss: 16.7939 - accuracy: 0.9786 - val_loss: 1161.4844 - val_accuracy: 0.6667\n",
            "1/1 [==============================] - 1s 592ms/step\n",
            "Epoch 1/20\n",
            "5/5 [==============================] - 7s 216ms/step - loss: 3233.9587 - accuracy: 0.5357 - val_loss: 220.2337 - val_accuracy: 0.7500\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 543.2095 - accuracy: 0.6857 - val_loss: 86.7154 - val_accuracy: 0.8333\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 320.9958 - accuracy: 0.7571 - val_loss: 206.3657 - val_accuracy: 0.9167\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 210.4552 - accuracy: 0.8214 - val_loss: 425.8684 - val_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 174.8507 - accuracy: 0.8429 - val_loss: 134.3619 - val_accuracy: 0.8333\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 204.4641 - accuracy: 0.7929 - val_loss: 141.9100 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 0s 61ms/step - loss: 89.3077 - accuracy: 0.8571 - val_loss: 481.6848 - val_accuracy: 0.7500\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 41.9065 - accuracy: 0.9286 - val_loss: 316.1659 - val_accuracy: 0.8333\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 0s 60ms/step - loss: 35.3126 - accuracy: 0.9286 - val_loss: 174.9755 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 29.7482 - accuracy: 0.9286 - val_loss: 725.1856 - val_accuracy: 0.6667\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 0s 68ms/step - loss: 65.1559 - accuracy: 0.9214 - val_loss: 147.3013 - val_accuracy: 0.8333\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 34.0029 - accuracy: 0.9500 - val_loss: 529.1930 - val_accuracy: 0.6667\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 11.5900 - accuracy: 0.9786 - val_loss: 182.8662 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 23.0471 - accuracy: 0.9214 - val_loss: 648.6691 - val_accuracy: 0.6667\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 4.5250 - accuracy: 0.9714 - val_loss: 321.5020 - val_accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 0s 62ms/step - loss: 16.2818 - accuracy: 0.9786 - val_loss: 399.8429 - val_accuracy: 0.6667\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 0s 77ms/step - loss: 26.1692 - accuracy: 0.9357 - val_loss: 530.7667 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 0s 73ms/step - loss: 26.8484 - accuracy: 0.9286 - val_loss: 191.8196 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 44.3277 - accuracy: 0.9357 - val_loss: 578.2106 - val_accuracy: 0.6667\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 0s 74ms/step - loss: 13.3267 - accuracy: 0.9714 - val_loss: 283.9977 - val_accuracy: 0.7500\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "Acurácia: 0.9454545454545455 +- 0.07272727272727272\n",
            "Recall: 0.9454545454545455 +- 0.07272727272727272\n",
            "Precisão: 0.9547474747474748 +- 0.05907286265049555\n",
            "F1: 0.9371004159239453 +- 0.08585354527985685\n"
          ]
        }
      ]
    }
  ]
}